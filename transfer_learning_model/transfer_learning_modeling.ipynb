{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9f3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications import ResNet50, xception, MobileNet, Xception, VGG16\n",
    "from tensorflow.keras.applications.resnet50  import preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e67202",
   "metadata": {},
   "source": [
    "### # dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59599aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 200, 150, 3) (14400, 200, 150, 3)\n",
      "(3600, 200, 150, 3) (3600, 200, 150, 3)\n",
      "(14400,) (3600,)\n"
     ]
    }
   ],
   "source": [
    "# import pickle5 as pickle\n",
    "\n",
    "# with open('E:/olive_young/CNN_transfer_learning/x_train.pickle',\"rb\") as fr:\n",
    "#     x_train = pickle.load(fr, encoding='bytes')\n",
    "# with open('E:/olive_young/CNN_transfer_learning/x_trn.pickle',\"rb\") as fr:\n",
    "#     x_trn = pickle.load(fr, encoding='bytes')\n",
    "# with open('E:/olive_young/CNN_transfer_learning/x_test.pickle',\"rb\") as fr:\n",
    "#     x_test = pickle.load(fr, encoding='bytes')\n",
    "# with open('E:/olive_young/CNN_transfer_learning/x_ts.pickle',\"rb\") as fr:\n",
    "#     x_ts  = pickle.load(fr, encoding='bytes')\n",
    "# with open('E:/olive_young/CNN_transfer_learning/y_train.pickle',\"rb\") as fr:\n",
    "#     y_train  = pickle.load(fr, encoding='bytes')\n",
    "# with open('E:/olive_young/CNN_transfer_learning/y_test.pickle',\"rb\") as fr:\n",
    "#     y_test  = pickle.load(fr, encoding='bytes')\n",
    "    \n",
    "x_train =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/x_train.pickle')\n",
    "x_trn =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/x_trn.pickle')\n",
    "x_test =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/x_test.pickle')\n",
    "x_ts =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/x_ts.pickle')\n",
    "y_train =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/y_train.pickle')\n",
    "y_test =  pd.read_pickle('E:/olive_young/CNN_transfer_learning/y_test.pickle')\n",
    "    \n",
    "print(x_train.shape, x_trn.shape)\n",
    "print(x_test.shape, x_ts.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04e23b",
   "metadata": {},
   "source": [
    "## # CNN Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005b184",
   "metadata": {},
   "source": [
    "* ResNet\n",
    "* MobileNet\n",
    "* VGGNet\n",
    "* Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ce45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(pre_trained_model):\n",
    "    # Some weights in later layers are unfreezed\n",
    "    for layer in pre_trained_model.layers[:-5]:\n",
    "        layer.trainable=False\n",
    "    model = pre_trained_model.output\n",
    "    model = AveragePooling2D(pool_size=(3,3))(model)\n",
    "    model = Flatten(name=\"flatten\")(model)\n",
    "    model = Dense(128,activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(30, activation='softmax')(model)\n",
    "    model = Model(inputs=pre_trained_model.input, outputs=model)\n",
    "    return model\n",
    "\n",
    "def model_compile(model, learning_rate):\n",
    "    sgd = SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss=['sparse_categorical_crossentropy'], \n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d549477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (x_trn.shape[1], x_trn.shape[2], 3)\n",
    "\n",
    "pre_resNet = ResNet50(input_shape=input_shape,\n",
    "                  include_top=False,\n",
    "                  weights=\"imagenet\")\n",
    "pre_mobileNet = MobileNet(input_shape=input_shape,\n",
    "                  include_top=False,\n",
    "                  weights=\"imagenet\")\n",
    "pre_vgg16= VGG16(input_shape=input_shape,\n",
    "                  include_top=False,\n",
    "                  weights=\"imagenet\")\n",
    "pre_xception = Xception(input_shape=input_shape,\n",
    "                  include_top=False,\n",
    "                  weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e0e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = pre_xception.output\n",
    "xception = AveragePooling2D(pool_size=(3,3))(xception)\n",
    "xception = Flatten(name=\"flatten\")(xception)\n",
    "xception = Dense(256,activation='relu')(xception)\n",
    "xception = Dense(128,activation='relu')(xception)\n",
    "xception = Dropout(0.5)(xception)\n",
    "xception = Dense(30, activation='softmax')(xception)\n",
    "xception = Model(inputs=pre_xception.input, outputs=xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c606162",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet = build_transfer_model(pre_resNet)\n",
    "mobileNet = build_transfer_model(pre_mobileNet)\n",
    "vgg16 = build_transfer_model(pre_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26ea6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet = model_compile(resNet, 0.001)\n",
    "mobileNet = model_compile(mobileNet, 0.001)\n",
    "vgg16 = model_compile(vgg16, 0.001)\n",
    "xception = model_compile(xception, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af50fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet_path = 'E:/olive_young/CNN_transfer_learning/models/resNet_best_model.h5'\n",
    "mobileNet_path = 'E:/olive_young/CNN_transfer_learning/models/mobileNet_best_model.h5'\n",
    "vgg16_path = 'E:/olive_young/CNN_transfer_learning/models/vgg16_best_model.h5'\n",
    "xception_path = 'E:/olive_young/CNN_transfer_learning/models/xception_best_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28cef1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_checkpoint_resNet = ModelCheckpoint(filepath=resNet_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)\n",
    "cb_checkpoint_mobileNet = ModelCheckpoint(filepath=mobileNet_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)\n",
    "cb_checkpoint_vgg16 = ModelCheckpoint(filepath=vgg16_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)\n",
    "cb_checkpoint_xception = ModelCheckpoint(filepath=xception_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3a6de",
   "metadata": {},
   "source": [
    "### # ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4074508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 206, 156, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 100, 75, 64)  9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 100, 75, 64)  256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 100, 75, 64)  0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 102, 77, 64)  0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 50, 38, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 50, 38, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 50, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 50, 38, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 50, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 50, 38, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 50, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 50, 38, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 50, 38, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 50, 38, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 50, 38, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 50, 38, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 50, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 50, 38, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 50, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 50, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 50, 38, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 50, 38, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 50, 38, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 50, 38, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 50, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 50, 38, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 50, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 50, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 50, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 50, 38, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 50, 38, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 50, 38, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 25, 19, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 25, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 25, 19, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 25, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 25, 19, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 25, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 25, 19, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 25, 19, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 25, 19, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 25, 19, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 25, 19, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 25, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 25, 19, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 25, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 25, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 25, 19, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 25, 19, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 25, 19, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 25, 19, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 25, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 25, 19, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 25, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 25, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 25, 19, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 25, 19, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 25, 19, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 25, 19, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 25, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 25, 19, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 25, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 25, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 25, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 25, 19, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 25, 19, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 25, 19, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 13, 10, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 13, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 13, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 13, 10, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 13, 10, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 13, 10, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 13, 10, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 13, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 13, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 13, 10, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 13, 10, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 13, 10, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 13, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 13, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 13, 10, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 13, 10, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 13, 10, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 13, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 13, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 13, 10, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 13, 10, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 13, 10, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 13, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 13, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 13, 10, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 13, 10, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 13, 10, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 13, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 13, 10, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 13, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 13, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 13, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 13, 10, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 13, 10, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 13, 10, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 5, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 5, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 5, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 5, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 5, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 5, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 5, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 5, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 5, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 5, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 5, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 5, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 5, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 5, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 5, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 5, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 5, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 2, 1, 2048)   0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          524416      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           3870        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,115,998\n",
      "Trainable params: 1,583,006\n",
      "Non-trainable params: 22,532,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "850d4482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "360/360 [==============================] - 75s 163ms/step - loss: 3.4031 - accuracy: 0.0359 - val_loss: 3.3948 - val_accuracy: 0.0385\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03854, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 2/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.3844 - accuracy: 0.0431 - val_loss: 3.3697 - val_accuracy: 0.0573\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.03854 to 0.05729, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 3/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.3584 - accuracy: 0.0543 - val_loss: 3.3492 - val_accuracy: 0.0660\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.05729 to 0.06597, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 4/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.3193 - accuracy: 0.0566 - val_loss: 3.2784 - val_accuracy: 0.0892\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.06597 to 0.08924, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 5/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.2741 - accuracy: 0.0690 - val_loss: 3.2177 - val_accuracy: 0.1035\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.08924 to 0.10347, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 6/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.2238 - accuracy: 0.0816 - val_loss: 3.1633 - val_accuracy: 0.1167\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.10347 to 0.11667, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 7/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 3.1692 - accuracy: 0.0944 - val_loss: 3.0925 - val_accuracy: 0.1441\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.11667 to 0.14410, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 8/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 3.1059 - accuracy: 0.1142 - val_loss: 2.9883 - val_accuracy: 0.1760\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.14410 to 0.17604, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 9/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 3.0492 - accuracy: 0.1331 - val_loss: 2.9414 - val_accuracy: 0.1764\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.17604 to 0.17639, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 10/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.9751 - accuracy: 0.1418 - val_loss: 2.8665 - val_accuracy: 0.2243\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.17639 to 0.22431, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 11/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.9169 - accuracy: 0.1626 - val_loss: 2.8107 - val_accuracy: 0.2174\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.22431\n",
      "Epoch 12/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.8583 - accuracy: 0.1813 - val_loss: 2.7537 - val_accuracy: 0.2156\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.22431\n",
      "Epoch 13/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.7993 - accuracy: 0.1961 - val_loss: 2.6450 - val_accuracy: 0.2622\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.22431 to 0.26215, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 14/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.7476 - accuracy: 0.2082 - val_loss: 2.6296 - val_accuracy: 0.2910\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.26215 to 0.29097, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 15/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.7039 - accuracy: 0.2181 - val_loss: 2.6035 - val_accuracy: 0.2781\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.29097\n",
      "Epoch 16/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.6739 - accuracy: 0.2247 - val_loss: 2.6335 - val_accuracy: 0.2816\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.29097\n",
      "Epoch 17/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.6288 - accuracy: 0.2411 - val_loss: 2.5701 - val_accuracy: 0.2681\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.29097\n",
      "Epoch 18/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.5882 - accuracy: 0.2542 - val_loss: 2.5003 - val_accuracy: 0.3059\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.29097 to 0.30590, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 19/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.5710 - accuracy: 0.2580 - val_loss: 2.4954 - val_accuracy: 0.2809\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.30590\n",
      "Epoch 20/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.5372 - accuracy: 0.2680 - val_loss: 2.4851 - val_accuracy: 0.3083\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.30590 to 0.30833, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 21/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.5085 - accuracy: 0.2736 - val_loss: 2.4312 - val_accuracy: 0.3233\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.30833 to 0.32326, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 22/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.4730 - accuracy: 0.2806 - val_loss: 2.4451 - val_accuracy: 0.3128\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.32326\n",
      "Epoch 23/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.4462 - accuracy: 0.2898 - val_loss: 2.3392 - val_accuracy: 0.3330\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.32326 to 0.33299, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 24/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.4150 - accuracy: 0.3036 - val_loss: 2.3896 - val_accuracy: 0.3250\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.33299\n",
      "Epoch 25/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.4034 - accuracy: 0.3057 - val_loss: 2.4024 - val_accuracy: 0.3208\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.33299\n",
      "Epoch 26/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.3727 - accuracy: 0.3111 - val_loss: 2.2897 - val_accuracy: 0.3646\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.33299 to 0.36458, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 27/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.3410 - accuracy: 0.3167 - val_loss: 2.3379 - val_accuracy: 0.3483\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.36458\n",
      "Epoch 28/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.3274 - accuracy: 0.3302 - val_loss: 2.2531 - val_accuracy: 0.3760\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.36458 to 0.37604, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 29/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.3083 - accuracy: 0.3291 - val_loss: 2.4197 - val_accuracy: 0.3083\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.37604\n",
      "Epoch 30/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.2914 - accuracy: 0.3346 - val_loss: 2.2624 - val_accuracy: 0.3604\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.37604\n",
      "Epoch 31/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.2952 - accuracy: 0.3399 - val_loss: 2.3133 - val_accuracy: 0.3399\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.37604\n",
      "Epoch 32/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.2569 - accuracy: 0.3444 - val_loss: 2.2174 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.37604 to 0.39132, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 33/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.2546 - accuracy: 0.3440 - val_loss: 2.1475 - val_accuracy: 0.4111\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.39132 to 0.41111, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 34/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.2136 - accuracy: 0.3617 - val_loss: 2.2830 - val_accuracy: 0.3503\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.41111\n",
      "Epoch 35/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.1932 - accuracy: 0.3609 - val_loss: 2.2951 - val_accuracy: 0.3517\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.41111\n",
      "Epoch 36/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.1875 - accuracy: 0.3674 - val_loss: 2.3081 - val_accuracy: 0.3330\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.41111\n",
      "Epoch 37/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.1705 - accuracy: 0.3715 - val_loss: 2.1386 - val_accuracy: 0.3976\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.41111\n",
      "Epoch 38/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 2.1533 - accuracy: 0.3712 - val_loss: 2.7437 - val_accuracy: 0.2552\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.41111\n",
      "Epoch 39/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.1278 - accuracy: 0.3766 - val_loss: 2.0439 - val_accuracy: 0.4410\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.41111 to 0.44097, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 40/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.1231 - accuracy: 0.3836 - val_loss: 2.1329 - val_accuracy: 0.3979\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.44097\n",
      "Epoch 41/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0976 - accuracy: 0.3921 - val_loss: 2.1122 - val_accuracy: 0.3955\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.44097\n",
      "Epoch 42/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.1011 - accuracy: 0.3933 - val_loss: 2.0201 - val_accuracy: 0.4361\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.44097\n",
      "Epoch 43/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0878 - accuracy: 0.3924 - val_loss: 2.0860 - val_accuracy: 0.4080\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.44097\n",
      "Epoch 44/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0654 - accuracy: 0.3942 - val_loss: 2.1320 - val_accuracy: 0.3972\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.44097\n",
      "Epoch 45/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0473 - accuracy: 0.4004 - val_loss: 2.0369 - val_accuracy: 0.4319\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.44097\n",
      "Epoch 46/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0295 - accuracy: 0.4062 - val_loss: 1.9757 - val_accuracy: 0.4458\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.44097 to 0.44583, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 47/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0252 - accuracy: 0.4077 - val_loss: 2.0515 - val_accuracy: 0.4219\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.44583\n",
      "Epoch 48/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 2.0158 - accuracy: 0.4132 - val_loss: 2.0195 - val_accuracy: 0.4215\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.44583\n",
      "Epoch 49/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9927 - accuracy: 0.4155 - val_loss: 2.0241 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.44583\n",
      "Epoch 50/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9895 - accuracy: 0.4174 - val_loss: 2.1599 - val_accuracy: 0.3806\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.44583\n",
      "Epoch 51/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9639 - accuracy: 0.4284 - val_loss: 2.0956 - val_accuracy: 0.3920\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.44583\n",
      "Epoch 52/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9614 - accuracy: 0.4232 - val_loss: 2.0292 - val_accuracy: 0.4035\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.44583\n",
      "Epoch 53/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9405 - accuracy: 0.4337 - val_loss: 1.9485 - val_accuracy: 0.4681\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.44583 to 0.46806, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 54/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9321 - accuracy: 0.4392 - val_loss: 1.9632 - val_accuracy: 0.4247\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.46806\n",
      "Epoch 55/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9190 - accuracy: 0.4394 - val_loss: 2.1251 - val_accuracy: 0.4056\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.46806\n",
      "Epoch 56/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.9059 - accuracy: 0.4430 - val_loss: 2.2866 - val_accuracy: 0.3493\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.46806\n",
      "Epoch 57/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8986 - accuracy: 0.4422 - val_loss: 1.9772 - val_accuracy: 0.4479\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.46806\n",
      "Epoch 58/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8741 - accuracy: 0.4525 - val_loss: 2.0544 - val_accuracy: 0.4160\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.46806\n",
      "Epoch 59/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8764 - accuracy: 0.4556 - val_loss: 2.0079 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.46806\n",
      "Epoch 60/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8644 - accuracy: 0.4507 - val_loss: 1.9906 - val_accuracy: 0.4323\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.46806\n",
      "Epoch 61/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8512 - accuracy: 0.4580 - val_loss: 1.8448 - val_accuracy: 0.4854\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.46806 to 0.48542, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 62/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8390 - accuracy: 0.4622 - val_loss: 2.0630 - val_accuracy: 0.3951\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.48542\n",
      "Epoch 63/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8248 - accuracy: 0.4666 - val_loss: 1.8786 - val_accuracy: 0.4757\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.48542\n",
      "Epoch 64/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8215 - accuracy: 0.4714 - val_loss: 2.0017 - val_accuracy: 0.4306\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.48542\n",
      "Epoch 65/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.8162 - accuracy: 0.4659 - val_loss: 2.0115 - val_accuracy: 0.4135\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.48542\n",
      "Epoch 66/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7841 - accuracy: 0.4749 - val_loss: 1.8319 - val_accuracy: 0.4806\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.48542\n",
      "Epoch 67/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7605 - accuracy: 0.4820 - val_loss: 1.9319 - val_accuracy: 0.4521\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.48542\n",
      "Epoch 68/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7595 - accuracy: 0.4812 - val_loss: 2.0047 - val_accuracy: 0.4271\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.48542\n",
      "Epoch 69/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7435 - accuracy: 0.4902 - val_loss: 1.7876 - val_accuracy: 0.4941\n",
      "\n",
      "Epoch 00069: val_accuracy improved from 0.48542 to 0.49410, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 70/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7429 - accuracy: 0.4849 - val_loss: 1.8300 - val_accuracy: 0.4729\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.49410\n",
      "Epoch 71/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7446 - accuracy: 0.4855 - val_loss: 1.8514 - val_accuracy: 0.4733\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.49410\n",
      "Epoch 72/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7271 - accuracy: 0.4931 - val_loss: 1.9497 - val_accuracy: 0.4410\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.49410\n",
      "Epoch 73/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7258 - accuracy: 0.4877 - val_loss: 1.8672 - val_accuracy: 0.4597\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.49410\n",
      "Epoch 74/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.7054 - accuracy: 0.5016 - val_loss: 1.9501 - val_accuracy: 0.4330\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.49410\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6939 - accuracy: 0.5006 - val_loss: 2.0674 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.49410\n",
      "Epoch 76/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6704 - accuracy: 0.5054 - val_loss: 1.8334 - val_accuracy: 0.4688\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.49410\n",
      "Epoch 77/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6772 - accuracy: 0.5073 - val_loss: 1.8620 - val_accuracy: 0.4573\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.49410\n",
      "Epoch 78/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6719 - accuracy: 0.5048 - val_loss: 1.8941 - val_accuracy: 0.4694\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.49410\n",
      "Epoch 79/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6505 - accuracy: 0.5116 - val_loss: 1.8490 - val_accuracy: 0.4611\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.49410\n",
      "Epoch 80/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6365 - accuracy: 0.5216 - val_loss: 1.7765 - val_accuracy: 0.4969\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.49410 to 0.49687, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 81/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6500 - accuracy: 0.5127 - val_loss: 1.7594 - val_accuracy: 0.5038\n",
      "\n",
      "Epoch 00081: val_accuracy improved from 0.49687 to 0.50382, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 82/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6093 - accuracy: 0.5279 - val_loss: 1.8631 - val_accuracy: 0.4747\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.50382\n",
      "Epoch 83/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.6001 - accuracy: 0.5237 - val_loss: 1.7836 - val_accuracy: 0.5042\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.50382 to 0.50417, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 84/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.6031 - accuracy: 0.5281 - val_loss: 1.9469 - val_accuracy: 0.4569\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.50417\n",
      "Epoch 85/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.5839 - accuracy: 0.5350 - val_loss: 1.7844 - val_accuracy: 0.4736\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.50417\n",
      "Epoch 86/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.5804 - accuracy: 0.5376 - val_loss: 1.7757 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.50417\n",
      "Epoch 87/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5578 - accuracy: 0.5365 - val_loss: 1.7098 - val_accuracy: 0.5104\n",
      "\n",
      "Epoch 00087: val_accuracy improved from 0.50417 to 0.51042, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 88/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5713 - accuracy: 0.5377 - val_loss: 1.8497 - val_accuracy: 0.4670\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.51042\n",
      "Epoch 89/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5508 - accuracy: 0.5412 - val_loss: 1.8722 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.51042\n",
      "Epoch 90/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5444 - accuracy: 0.5460 - val_loss: 2.0446 - val_accuracy: 0.4212\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.51042\n",
      "Epoch 91/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5440 - accuracy: 0.5458 - val_loss: 1.7317 - val_accuracy: 0.5118\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.51042 to 0.51181, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 92/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5401 - accuracy: 0.5474 - val_loss: 1.7997 - val_accuracy: 0.4812\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.51181\n",
      "Epoch 93/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5231 - accuracy: 0.5528 - val_loss: 1.7577 - val_accuracy: 0.4851\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.51181\n",
      "Epoch 94/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.5065 - accuracy: 0.5523 - val_loss: 1.7160 - val_accuracy: 0.5253\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.51181 to 0.52535, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 95/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4959 - accuracy: 0.5585 - val_loss: 1.7739 - val_accuracy: 0.4997\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.52535\n",
      "Epoch 96/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4876 - accuracy: 0.5596 - val_loss: 1.7842 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.52535\n",
      "Epoch 97/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4770 - accuracy: 0.5631 - val_loss: 1.7826 - val_accuracy: 0.4899\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.52535\n",
      "Epoch 98/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4741 - accuracy: 0.5608 - val_loss: 1.7586 - val_accuracy: 0.4920\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.52535\n",
      "Epoch 99/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4590 - accuracy: 0.5701 - val_loss: 1.7230 - val_accuracy: 0.5108\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.52535\n",
      "Epoch 100/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4479 - accuracy: 0.5728 - val_loss: 1.6358 - val_accuracy: 0.5340\n",
      "\n",
      "Epoch 00100: val_accuracy improved from 0.52535 to 0.53403, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 101/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.4452 - accuracy: 0.5734 - val_loss: 1.7472 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.53403\n",
      "Epoch 102/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4373 - accuracy: 0.5730 - val_loss: 1.7118 - val_accuracy: 0.5104\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.53403\n",
      "Epoch 103/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.4141 - accuracy: 0.5770 - val_loss: 1.7300 - val_accuracy: 0.5167\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.53403\n",
      "Epoch 104/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.4186 - accuracy: 0.5732 - val_loss: 1.9821 - val_accuracy: 0.4472\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.53403\n",
      "Epoch 105/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.4086 - accuracy: 0.5841 - val_loss: 1.8376 - val_accuracy: 0.4767\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.53403\n",
      "Epoch 106/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.4056 - accuracy: 0.5821 - val_loss: 1.8464 - val_accuracy: 0.4826\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.53403\n",
      "Epoch 107/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3835 - accuracy: 0.5880 - val_loss: 1.6937 - val_accuracy: 0.5115\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.53403\n",
      "Epoch 108/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3859 - accuracy: 0.5835 - val_loss: 1.6356 - val_accuracy: 0.5406\n",
      "\n",
      "Epoch 00108: val_accuracy improved from 0.53403 to 0.54062, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 109/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3710 - accuracy: 0.5969 - val_loss: 1.6234 - val_accuracy: 0.5392\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.54062\n",
      "Epoch 110/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3633 - accuracy: 0.5924 - val_loss: 1.8377 - val_accuracy: 0.4771\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.54062\n",
      "Epoch 111/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.3478 - accuracy: 0.6023 - val_loss: 2.0035 - val_accuracy: 0.4410\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.54062\n",
      "Epoch 112/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3471 - accuracy: 0.5977 - val_loss: 1.7650 - val_accuracy: 0.4962\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.54062\n",
      "Epoch 113/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3504 - accuracy: 0.5991 - val_loss: 1.5999 - val_accuracy: 0.5590\n",
      "\n",
      "Epoch 00113: val_accuracy improved from 0.54062 to 0.55903, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 114/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3339 - accuracy: 0.5988 - val_loss: 1.6517 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.55903\n",
      "Epoch 115/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3246 - accuracy: 0.6068 - val_loss: 1.7594 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.55903\n",
      "Epoch 116/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3177 - accuracy: 0.6092 - val_loss: 1.6473 - val_accuracy: 0.5188\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.55903\n",
      "Epoch 117/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3178 - accuracy: 0.6090 - val_loss: 1.6651 - val_accuracy: 0.5264\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.55903\n",
      "Epoch 118/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.2942 - accuracy: 0.6131 - val_loss: 1.8629 - val_accuracy: 0.4927\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.55903\n",
      "Epoch 119/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.3099 - accuracy: 0.6118 - val_loss: 1.5910 - val_accuracy: 0.5490\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.55903\n",
      "Epoch 120/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.2828 - accuracy: 0.6186 - val_loss: 1.6374 - val_accuracy: 0.5382\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.55903\n",
      "Epoch 121/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.2819 - accuracy: 0.6161 - val_loss: 1.6972 - val_accuracy: 0.5191\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.55903\n",
      "Epoch 122/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.2728 - accuracy: 0.6191 - val_loss: 1.7151 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.55903\n",
      "Epoch 123/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2735 - accuracy: 0.6203 - val_loss: 1.6852 - val_accuracy: 0.5212\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.55903\n",
      "Epoch 124/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2654 - accuracy: 0.6227 - val_loss: 1.6627 - val_accuracy: 0.5205\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.55903\n",
      "Epoch 125/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2467 - accuracy: 0.6284 - val_loss: 1.7090 - val_accuracy: 0.5160\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.55903\n",
      "Epoch 126/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2447 - accuracy: 0.6327 - val_loss: 1.6558 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.55903\n",
      "Epoch 127/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2364 - accuracy: 0.6280 - val_loss: 2.1978 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.55903\n",
      "Epoch 128/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2250 - accuracy: 0.6322 - val_loss: 1.6015 - val_accuracy: 0.5510\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.55903\n",
      "Epoch 129/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2252 - accuracy: 0.6334 - val_loss: 1.6630 - val_accuracy: 0.5267\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.55903\n",
      "Epoch 130/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2275 - accuracy: 0.6315 - val_loss: 1.6671 - val_accuracy: 0.5389\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.55903\n",
      "Epoch 131/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.2067 - accuracy: 0.6378 - val_loss: 1.5826 - val_accuracy: 0.5490\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.55903\n",
      "Epoch 132/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1966 - accuracy: 0.6357 - val_loss: 1.5820 - val_accuracy: 0.5566\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.55903\n",
      "Epoch 133/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1865 - accuracy: 0.6449 - val_loss: 1.6798 - val_accuracy: 0.5222\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.55903\n",
      "Epoch 134/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1691 - accuracy: 0.6515 - val_loss: 1.9726 - val_accuracy: 0.4618\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.55903\n",
      "Epoch 135/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1729 - accuracy: 0.6456 - val_loss: 1.8105 - val_accuracy: 0.4951\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.55903\n",
      "Epoch 136/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1679 - accuracy: 0.6512 - val_loss: 1.5695 - val_accuracy: 0.5583\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.55903\n",
      "Epoch 137/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1658 - accuracy: 0.6510 - val_loss: 1.6455 - val_accuracy: 0.5378\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.55903\n",
      "Epoch 138/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1505 - accuracy: 0.6574 - val_loss: 1.8049 - val_accuracy: 0.5101\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.55903\n",
      "Epoch 139/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1687 - accuracy: 0.6482 - val_loss: 1.5909 - val_accuracy: 0.5542\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.55903\n",
      "Epoch 140/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.1509 - accuracy: 0.6563 - val_loss: 1.6882 - val_accuracy: 0.5312\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.55903\n",
      "Epoch 141/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.1435 - accuracy: 0.6560 - val_loss: 1.7230 - val_accuracy: 0.5135\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.55903\n",
      "Epoch 142/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1407 - accuracy: 0.6576 - val_loss: 1.7317 - val_accuracy: 0.5122\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.55903\n",
      "Epoch 143/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1283 - accuracy: 0.6539 - val_loss: 1.6245 - val_accuracy: 0.5424\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.55903\n",
      "Epoch 144/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.1247 - accuracy: 0.6595 - val_loss: 1.7456 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.55903\n",
      "Epoch 145/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1275 - accuracy: 0.6602 - val_loss: 1.5590 - val_accuracy: 0.5608\n",
      "\n",
      "Epoch 00145: val_accuracy improved from 0.55903 to 0.56076, saving model to D:/dasol\\resNet_best_model.h5\n",
      "Epoch 146/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.1069 - accuracy: 0.6716 - val_loss: 1.7136 - val_accuracy: 0.5198\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.56076\n",
      "Epoch 147/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.0995 - accuracy: 0.6687 - val_loss: 2.0213 - val_accuracy: 0.4594\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.56076\n",
      "Epoch 148/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.0843 - accuracy: 0.6739 - val_loss: 1.5665 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.56076\n",
      "Epoch 149/150\n",
      "360/360 [==============================] - 45s 124ms/step - loss: 1.0840 - accuracy: 0.6707 - val_loss: 1.5879 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.56076\n",
      "Epoch 150/150\n",
      "360/360 [==============================] - 45s 125ms/step - loss: 1.0763 - accuracy: 0.6806 - val_loss: 1.6870 - val_accuracy: 0.5340\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.56076\n"
     ]
    }
   ],
   "source": [
    "resNet_history = resNet.fit(x_trn, y_train, \n",
    "                    validation_split=0.2, shuffle=True,\n",
    "                    epochs=150, batch_size=32, callbacks=[cb_checkpoint_resNet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f95df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resNet_acc = resNet_history.history['accuracy']\n",
    "resNet_val_acc = resNet_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(resNet_acc)+1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('resNet_ Accuracy')\n",
    "plt.plot(epochs, resNet_acc, 'b', label='train_acc')\n",
    "plt.plot(epochs, resNet_val_acc, 'r', label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfdc79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 186s 2s/step - loss: 1.5313 - accuracy: 0.5639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.531251072883606, 0.5638889074325562]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_resNet = load_model(resNet_path)\n",
    "resNet_test_res = best_resNet.evaluate(x_ts, y_test)\n",
    "resNet_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d213a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 144s 1s/step\n",
      "time : 144.45266723632812\n",
      "pred shape: (3600, 30)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pred = best_resNet.predict(x_ts)\n",
    "resNet_pred_time = time.time()-start_time\n",
    "print(\"time : {}\".format(resNet_pred_time))\n",
    "print(\"pred shape:\", pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e836c1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.974989652633667\n"
     ]
    }
   ],
   "source": [
    "# test image 1장 예측 시간\n",
    "temp = x_ts[1].reshape(1, 200, 150, 3)\n",
    "start_time = time.time()\n",
    "p = best_resNet.predict(temp)\n",
    "print(\"time : {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64599574",
   "metadata": {},
   "source": [
    "### # MobileNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c166baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 200, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 100, 75, 32)       864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 100, 75, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 100, 75, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 100, 75, 32)       288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 100, 75, 32)       128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 100, 75, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 100, 75, 64)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 100, 75, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 100, 75, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 101, 76, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 50, 37, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 50, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 50, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 50, 37, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 50, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 50, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 50, 37, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 50, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 50, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 50, 37, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 50, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 50, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 51, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 25, 18, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 25, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 25, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 25, 18, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 25, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 25, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 25, 18, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 25, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 25, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 25, 18, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 25, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 25, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 26, 19, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 12, 9, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 12, 9, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 12, 9, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 12, 9, 512)        131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 12, 9, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 12, 9, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 12, 9, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 12, 9, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 12, 9, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 12, 9, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 12, 9, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 12, 9, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 12, 9, 512)        4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 12, 9, 512)        262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 12, 9, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 13, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 6, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 6, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 6, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 6, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 6, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 6, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 6, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 6, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 6, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 6, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 6, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 6, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 2, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 3,495,006\n",
      "Trainable params: 1,318,814\n",
      "Non-trainable params: 2,176,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobileNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9251009a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "360/360 [==============================] - 36s 77ms/step - loss: 1.9030 - accuracy: 0.4756 - val_loss: 0.4606 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89965, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 2/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.6329 - accuracy: 0.8157 - val_loss: 0.2403 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.89965 to 0.93889, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 3/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.3809 - accuracy: 0.8881 - val_loss: 0.1773 - val_accuracy: 0.9531\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.93889 to 0.95312, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 4/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.2707 - accuracy: 0.9221 - val_loss: 0.1426 - val_accuracy: 0.9576\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.95312 to 0.95764, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 5/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.2063 - accuracy: 0.9391 - val_loss: 0.1249 - val_accuracy: 0.9608\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.95764 to 0.96076, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 6/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.1601 - accuracy: 0.9543 - val_loss: 0.1148 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.96076 to 0.96528, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 7/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.1291 - accuracy: 0.9631 - val_loss: 0.1009 - val_accuracy: 0.9660\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.96528 to 0.96597, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 8/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.1072 - accuracy: 0.9719 - val_loss: 0.0986 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.96597 to 0.96910, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 9/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.1075 - accuracy: 0.9685 - val_loss: 0.0890 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.96910 to 0.97257, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 10/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0830 - accuracy: 0.9784 - val_loss: 0.0865 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97257\n",
      "Epoch 11/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0755 - accuracy: 0.9794 - val_loss: 0.0875 - val_accuracy: 0.9729\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.97257 to 0.97292, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 12/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.0839 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97292\n",
      "Epoch 13/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.0819 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97292\n",
      "Epoch 14/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0538 - accuracy: 0.9852 - val_loss: 0.0824 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97292\n",
      "Epoch 15/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0475 - accuracy: 0.9889 - val_loss: 0.0795 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97292\n",
      "Epoch 16/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 0.0783 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.97292 to 0.97465, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 17/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0452 - accuracy: 0.9870 - val_loss: 0.0760 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97465\n",
      "Epoch 18/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0362 - accuracy: 0.9913 - val_loss: 0.0734 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.97465 to 0.97535, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 19/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0730 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97535\n",
      "Epoch 20/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 0.0747 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97535\n",
      "Epoch 21/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.0731 - val_accuracy: 0.9760\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.97535 to 0.97604, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 22/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.0705 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.97604\n",
      "Epoch 23/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.0712 - val_accuracy: 0.9767\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.97604 to 0.97674, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 24/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0293 - accuracy: 0.9923 - val_loss: 0.0696 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.97674\n",
      "Epoch 25/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0706 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.97674\n",
      "Epoch 26/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0233 - accuracy: 0.9954 - val_loss: 0.0691 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97674\n",
      "Epoch 27/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0705 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.97674\n",
      "Epoch 28/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.0703 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97674\n",
      "Epoch 29/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0231 - accuracy: 0.9947 - val_loss: 0.0720 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.97674 to 0.97847, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 30/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.0689 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.97847\n",
      "Epoch 31/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.0669 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.97847\n",
      "Epoch 32/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 0.0669 - val_accuracy: 0.9774\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97847\n",
      "Epoch 33/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0181 - accuracy: 0.9960 - val_loss: 0.0681 - val_accuracy: 0.9767\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97847\n",
      "Epoch 34/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.0697 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.97847\n",
      "Epoch 35/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.97847\n",
      "Epoch 36/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0680 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97847\n",
      "Epoch 37/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.0668 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97847\n",
      "Epoch 38/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.0682 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.97847\n",
      "Epoch 39/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.0667 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97847\n",
      "Epoch 40/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0683 - val_accuracy: 0.9774\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97847\n",
      "Epoch 41/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0679 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.97847 to 0.97917, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 42/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97917\n",
      "Epoch 43/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0667 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.97917\n",
      "Epoch 44/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.0653 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.97917\n",
      "Epoch 45/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.0646 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.97917\n",
      "Epoch 46/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0647 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.97917\n",
      "Epoch 47/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0646 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.97917 to 0.98021, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 48/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0656 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98021\n",
      "Epoch 49/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0661 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98021\n",
      "Epoch 50/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0653 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98021\n",
      "Epoch 51/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0661 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.98021\n",
      "Epoch 52/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0644 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.98021\n",
      "Epoch 53/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0636 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.98021\n",
      "Epoch 54/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0650 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.98021\n",
      "Epoch 55/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0641 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.98021\n",
      "Epoch 56/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.0623 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.98021\n",
      "Epoch 57/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.0644 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.98021\n",
      "Epoch 58/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0663 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.98021\n",
      "Epoch 59/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0652 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.98021\n",
      "Epoch 60/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0645 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.98021\n",
      "Epoch 61/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0636 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.98021\n",
      "Epoch 62/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0636 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.98021\n",
      "Epoch 63/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0641 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.98021\n",
      "Epoch 64/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0659 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.98021\n",
      "Epoch 65/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0659 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.98021\n",
      "Epoch 66/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0646 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.98021\n",
      "Epoch 67/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0646 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.98021\n",
      "Epoch 68/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0628 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.98021\n",
      "Epoch 69/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0651 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.98021\n",
      "Epoch 70/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0659 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.98021\n",
      "Epoch 71/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0641 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.98021\n",
      "Epoch 72/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.98021 to 0.98090, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 73/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0658 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.98090\n",
      "Epoch 74/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0656 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.98090 to 0.98160, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 75/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0636 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.98160\n",
      "Epoch 76/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0631 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.98160\n",
      "Epoch 77/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0625 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.98160\n",
      "Epoch 78/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0637 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.98160\n",
      "Epoch 79/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0641 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.98160\n",
      "Epoch 80/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.98160\n",
      "Epoch 81/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0626 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.98160\n",
      "Epoch 82/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0646 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.98160\n",
      "Epoch 83/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0634 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.98160\n",
      "Epoch 84/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0644 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.98160\n",
      "Epoch 85/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0648 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.98160\n",
      "Epoch 86/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0643 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.98160\n",
      "Epoch 87/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.98160\n",
      "Epoch 88/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0637 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.98160\n",
      "Epoch 89/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0632 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.98160\n",
      "Epoch 90/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0631 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.98160\n",
      "Epoch 91/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0626 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.98160\n",
      "Epoch 92/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0634 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.98160\n",
      "Epoch 93/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0639 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.98160\n",
      "Epoch 94/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0639 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.98160\n",
      "Epoch 95/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0635 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.98160\n",
      "Epoch 96/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0639 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.98160\n",
      "Epoch 97/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0633 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.98160\n",
      "Epoch 98/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.98160\n",
      "Epoch 99/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.98160\n",
      "Epoch 100/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0629 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.98160\n",
      "Epoch 101/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0637 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.98160\n",
      "Epoch 102/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0639 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.98160\n",
      "Epoch 103/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.98160\n",
      "Epoch 104/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0641 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.98160\n",
      "Epoch 105/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0648 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.98160\n",
      "Epoch 106/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0657 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.98160\n",
      "Epoch 107/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0655 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.98160\n",
      "Epoch 108/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0648 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.98160\n",
      "Epoch 109/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.98160\n",
      "Epoch 110/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.98160\n",
      "Epoch 111/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0648 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.98160\n",
      "Epoch 112/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0663 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.98160\n",
      "Epoch 113/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0658 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.98160\n",
      "Epoch 114/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0652 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.98160\n",
      "Epoch 115/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0646 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.98160\n",
      "Epoch 116/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.98160\n",
      "Epoch 117/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0641 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.98160\n",
      "Epoch 118/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0640 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.98160\n",
      "Epoch 119/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0636 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.98160\n",
      "Epoch 120/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.98160\n",
      "Epoch 121/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0638 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.98160\n",
      "Epoch 122/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0637 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.98160\n",
      "Epoch 123/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0622 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.98160\n",
      "Epoch 124/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0618 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.98160\n",
      "Epoch 125/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0642 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.98160\n",
      "Epoch 126/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0643 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.98160\n",
      "Epoch 127/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0617 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.98160\n",
      "Epoch 128/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0618 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.98160\n",
      "Epoch 129/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0626 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.98160\n",
      "Epoch 130/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0632 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.98160\n",
      "Epoch 131/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0642 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.98160\n",
      "Epoch 132/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0634 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00132: val_accuracy improved from 0.98160 to 0.98194, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 133/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0624 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00133: val_accuracy improved from 0.98194 to 0.98264, saving model to D:/dasol\\mobileNet_best_model.h5\n",
      "Epoch 134/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.98264\n",
      "Epoch 135/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0635 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.98264\n",
      "Epoch 136/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0638 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.98264\n",
      "Epoch 137/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0640 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.98264\n",
      "Epoch 138/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0625 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.98264\n",
      "Epoch 139/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0636 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.98264\n",
      "Epoch 140/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.98264\n",
      "Epoch 141/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0658 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.98264\n",
      "Epoch 142/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0652 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.98264\n",
      "Epoch 143/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0636 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.98264\n",
      "Epoch 144/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0632 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.98264\n",
      "Epoch 145/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0630 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.98264\n",
      "Epoch 146/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.98264\n",
      "Epoch 147/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0629 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.98264\n",
      "Epoch 148/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0632 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.98264\n",
      "Epoch 149/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0631 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.98264\n",
      "Epoch 150/150\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0650 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.98264\n"
     ]
    }
   ],
   "source": [
    "mobileNet_history = mobileNet.fit(x_trn, y_train, \n",
    "                    validation_split=0.2, shuffle=True,\n",
    "                    epochs=150, batch_size=32, callbacks=[cb_checkpoint_mobileNet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa2b9da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobileNet_acc = mobileNet_history.history['accuracy']\n",
    "mobileNet_val_acc = mobileNet_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(mobileNet_acc)+1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('mobileNet Accuracy')\n",
    "plt.plot(epochs, mobileNet_acc, 'b', label='train_acc')\n",
    "plt.plot(epochs, mobileNet_val_acc, 'r', label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64825428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 46s 403ms/step - loss: 0.0834 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08338188380002975, 0.9800000190734863]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mobileNet= load_model(mobileNet_path)\n",
    "mobileNet_test_res = best_mobileNet.evaluate(x_ts, y_test)\n",
    "mobileNet_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc195ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 34s 293ms/step\n",
      "time : 34.10746741294861\n",
      "pred shape: (3600, 30)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pred = best_mobileNet.predict(x_ts)\n",
    "mobileNet_pred_time = time.time()-start_time\n",
    "print(\"time : {}\".format(mobileNet_pred_time))\n",
    "print(\"pred shape:\", pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ee59914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.07154297828674316\n"
     ]
    }
   ],
   "source": [
    "# test image 1장 예측 시간\n",
    "temp = x_ts[1].reshape(1, 200, 150, 3)\n",
    "start_time = time.time()\n",
    "p = best_mobileNet.predict(temp)\n",
    "print(\"time : {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcaa3fd",
   "metadata": {},
   "source": [
    "### # VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7d595b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 200, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 75, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 75, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 75, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 9, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 9, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 9, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 9, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 2, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 14,849,758\n",
      "Trainable params: 7,214,494\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30107b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "360/360 [==============================] - 76s 189ms/step - loss: 2.3691 - accuracy: 0.3321 - val_loss: 0.7395 - val_accuracy: 0.8313\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83125, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 2/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.7595 - accuracy: 0.7823 - val_loss: 0.2806 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.83125 to 0.92778, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 3/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.4016 - accuracy: 0.8870 - val_loss: 0.1979 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.92778 to 0.94965, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 4/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.2771 - accuracy: 0.9232 - val_loss: 0.1384 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.94965 to 0.96285, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 5/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.1954 - accuracy: 0.9444 - val_loss: 0.1185 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96285 to 0.96528, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 6/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.1513 - accuracy: 0.9581 - val_loss: 0.1208 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.96528 to 0.97014, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 7/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.1236 - accuracy: 0.9652 - val_loss: 0.1199 - val_accuracy: 0.9663\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.97014\n",
      "Epoch 8/150\n",
      "360/360 [==============================] - 56s 157ms/step - loss: 0.0971 - accuracy: 0.9752 - val_loss: 0.0994 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.97014 to 0.97465, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 9/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0811 - accuracy: 0.9786 - val_loss: 0.1025 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.97465\n",
      "Epoch 10/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0699 - accuracy: 0.9799 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.97465 to 0.97778, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 11/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0588 - accuracy: 0.9845 - val_loss: 0.0985 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.97778\n",
      "Epoch 12/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 0.0797 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97778\n",
      "Epoch 13/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0402 - accuracy: 0.9911 - val_loss: 0.0878 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97778\n",
      "Epoch 14/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97778\n",
      "Epoch 15/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 0.0911 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97778\n",
      "Epoch 16/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.0835 - val_accuracy: 0.9774\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97778\n",
      "Epoch 17/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.0832 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.97778 to 0.98021, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 18/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0677 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98021\n",
      "Epoch 19/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.0769 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98021\n",
      "Epoch 20/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0817 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98021\n",
      "Epoch 21/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0750 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.98021 to 0.98090, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 22/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.0749 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98090\n",
      "Epoch 23/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0743 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.98090 to 0.98125, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 24/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.0897 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98125\n",
      "Epoch 25/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98125\n",
      "Epoch 26/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0710 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.98125 to 0.98194, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 27/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0704 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98194\n",
      "Epoch 28/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0740 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98194\n",
      "Epoch 29/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.0791 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98194\n",
      "Epoch 30/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0781 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98194\n",
      "Epoch 31/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0726 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98194\n",
      "Epoch 32/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0741 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98194\n",
      "Epoch 33/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0808 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98194\n",
      "Epoch 34/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0658 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.98194 to 0.98438, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 35/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0684 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98438\n",
      "Epoch 36/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0725 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.98438\n",
      "Epoch 37/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98438\n",
      "Epoch 38/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0733 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.98438\n",
      "Epoch 39/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0752 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98438\n",
      "Epoch 40/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0735 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98438\n",
      "Epoch 41/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0779 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98438\n",
      "Epoch 42/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0911 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98438\n",
      "Epoch 43/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0845 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.98438\n",
      "Epoch 44/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0818 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98438\n",
      "Epoch 45/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0795 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98438\n",
      "Epoch 46/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0789 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98438\n",
      "Epoch 47/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0824 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98438\n",
      "Epoch 48/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0822 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98438\n",
      "Epoch 49/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0764 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98438\n",
      "Epoch 50/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0734 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98438\n",
      "Epoch 51/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0776 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.98438\n",
      "Epoch 52/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0811 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.98438\n",
      "Epoch 53/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0710 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.98438\n",
      "Epoch 54/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0736 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.98438 to 0.98507, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 55/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0803 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.98507\n",
      "Epoch 56/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0775 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.98507\n",
      "Epoch 57/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0707 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.98507\n",
      "Epoch 58/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0815 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.98507\n",
      "Epoch 59/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.1001 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.98507\n",
      "Epoch 60/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0789 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.98507\n",
      "Epoch 61/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0767 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.98507\n",
      "Epoch 62/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0772 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.98507\n",
      "Epoch 63/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0740 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.98507\n",
      "Epoch 64/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0786 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.98507\n",
      "Epoch 65/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0732 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.98507\n",
      "Epoch 66/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0749 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.98507\n",
      "Epoch 67/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0782 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.98507\n",
      "Epoch 68/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0758 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.98507\n",
      "Epoch 69/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0741 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.98507\n",
      "Epoch 70/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0763 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.98507\n",
      "Epoch 71/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0804 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.98507\n",
      "Epoch 72/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0812 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.98507\n",
      "Epoch 73/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0813 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.98507\n",
      "Epoch 74/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0792 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.98507\n",
      "Epoch 75/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0842 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.98507\n",
      "Epoch 76/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1018 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.98507\n",
      "Epoch 77/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.98507\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0763 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.98507\n",
      "Epoch 79/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0740 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.98507\n",
      "Epoch 80/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0699 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.98507\n",
      "Epoch 81/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0696 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00081: val_accuracy improved from 0.98507 to 0.98542, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 82/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.98542\n",
      "Epoch 83/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0756 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.98542\n",
      "Epoch 84/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.98542\n",
      "Epoch 85/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0765 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.98542\n",
      "Epoch 86/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.98542\n",
      "Epoch 87/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0772 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.98542\n",
      "Epoch 88/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0894 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.98542\n",
      "Epoch 89/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0758 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.98542\n",
      "Epoch 90/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0807 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.98542\n",
      "Epoch 91/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0783 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.98542\n",
      "Epoch 92/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0782 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.98542\n",
      "Epoch 93/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0725 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.98542\n",
      "Epoch 94/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0815 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.98542\n",
      "Epoch 95/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0820 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.98542\n",
      "Epoch 96/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0718 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.98542\n",
      "Epoch 97/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0745 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.98542\n",
      "Epoch 98/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0744 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00098: val_accuracy improved from 0.98542 to 0.98715, saving model to D:/dasol\\vgg16_best_model.h5\n",
      "Epoch 99/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0782 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.98715\n",
      "Epoch 100/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0782 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.98715\n",
      "Epoch 101/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0774 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.98715\n",
      "Epoch 102/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0790 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.98715\n",
      "Epoch 103/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0840 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.98715\n",
      "Epoch 104/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0811 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.98715\n",
      "Epoch 105/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0818 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.98715\n",
      "Epoch 106/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0836 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.98715\n",
      "Epoch 107/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0787 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.98715\n",
      "Epoch 108/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0824 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.98715\n",
      "Epoch 109/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0808 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.98715\n",
      "Epoch 110/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0752 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.98715\n",
      "Epoch 111/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0824 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.98715\n",
      "Epoch 112/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0740 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.98715\n",
      "Epoch 113/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0757 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.98715\n",
      "Epoch 114/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0756 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.98715\n",
      "Epoch 115/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0774 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.98715\n",
      "Epoch 116/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0862 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.98715\n",
      "Epoch 117/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 9.6020e-04 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.98715\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0774 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.98715\n",
      "Epoch 119/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0805 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.98715\n",
      "Epoch 120/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0862 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.98715\n",
      "Epoch 121/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0830 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.98715\n",
      "Epoch 122/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0796 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.98715\n",
      "Epoch 123/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0875 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.98715\n",
      "Epoch 124/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0877 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.98715\n",
      "Epoch 125/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1031 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.98715\n",
      "Epoch 126/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0843 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.98715\n",
      "Epoch 127/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0842 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.98715\n",
      "Epoch 128/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0824 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.98715\n",
      "Epoch 129/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0718 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.98715\n",
      "Epoch 130/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0750 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.98715\n",
      "Epoch 131/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 8.9103e-04 - accuracy: 0.9999 - val_loss: 0.0836 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.98715\n",
      "Epoch 132/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0809 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.98715\n",
      "Epoch 133/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0811 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.98715\n",
      "Epoch 134/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0782 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.98715\n",
      "Epoch 135/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0873 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.98715\n",
      "Epoch 136/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 8.7240e-04 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.98715\n",
      "Epoch 137/150\n",
      "360/360 [==============================] - 56s 156ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0826 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.98715\n",
      "Epoch 138/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0897 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.98715\n",
      "Epoch 139/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0791 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.98715\n",
      "Epoch 140/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0913 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.98715\n",
      "Epoch 141/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 9.9121e-04 - accuracy: 0.9999 - val_loss: 0.0922 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.98715\n",
      "Epoch 142/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 8.0337e-04 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.98715\n",
      "Epoch 143/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 9.3004e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.98715\n",
      "Epoch 144/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0795 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.98715\n",
      "Epoch 145/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0862 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.98715\n",
      "Epoch 146/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 8.5046e-04 - accuracy: 0.9999 - val_loss: 0.0848 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.98715\n",
      "Epoch 147/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0937 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.98715\n",
      "Epoch 148/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0847 - val_accuracy: 0.9816\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.98715\n",
      "Epoch 149/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0850 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.98715\n",
      "Epoch 150/150\n",
      "360/360 [==============================] - 56s 155ms/step - loss: 7.3297e-04 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.98715\n"
     ]
    }
   ],
   "source": [
    "vgg16_history = vgg16.fit(x_trn, y_train, \n",
    "                    validation_split=0.2, shuffle=True,\n",
    "                    epochs=150, batch_size=32, callbacks=[cb_checkpoint_vgg16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46a132e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAF1CAYAAACu34FxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABc/UlEQVR4nO3deXhTVf4G8DdJ06ShLS10o6VQdiy7IFhQFGURsCK4dAShVAdF6bh0HJRRQHC06giCCOL4E5xREFxwA0RqERBBwAIqq6CshS5sXWmTJuf3x/EmTZu0uSVtKX0/z5Onzc1dTr7Z3px774lGCCFARERERFQHtPXdACIiIiJqPBg+iYiIiKjOMHwSERERUZ1h+CQiIiKiOsPwSURERER1huGTiIiIiOoMwycRERER1RmGTyIiIiKqMwyfRERERFRnGD6JiIiIqM4wfBLRVe3MmTN45plnMGjQIAQEBECj0WDjxo1u5zebzXjppZfQuXNnGI1GhIeHY+TIkTh16pRX29W3b19oNBq89dZbXl0vEdGVjuGTiK5qhw4dwiuvvILMzEx069atynktFgtGjhyJF198EbfddhsWLVqEqVOnokmTJsjLy/Namw4fPoydO3ciJiYGy5Yt89p6iYgaAp/6bgARUW3q3bs3zp07h2bNmuGTTz7BPffc43be119/HZs2bcKWLVvQt2/fWmvTBx98gLCwMMyZMwd33303jh07hpiYmFrbXk3ZbDaYzWYYjcb6bgoRXUXY80lEteqTTz6BRqPBpk2bKt329ttvQ6PRYO/evfZpH3/8MWJjY2E0GtG1a1d89tlnmDhxYqVwdu7cOYwfPx6BgYEICgpCYmIifv75Z2g0Grz33nv2+QICAtCsWbNq22mz2TB//nyMHj0affv2RVlZGYqLi2t8v6uyfPly3H333bj99tvRtGlTLF++3OV827dvx4gRIxAcHIwmTZqge/fumD9/vtM8Bw8exL333ovQ0FD4+fmhU6dOePbZZ+23u6odADz//PPQaDRO0zQaDZKTk7Fs2TJ06dIFBoMB69atAwC89tpr6N+/P5o3bw4/Pz/07t0bn3zyict2f/DBB+jbty9MJhOCg4MxcOBArF+/HgCQmJiIkJAQWCyWSssNHToUnTp1cl84IroqMHwSUa0aOXIk/P398dFHH1W6beXKlejSpQu6du0KAFizZg0SEhKg1+uRmpqKMWPG4MEHH0RGRobTcjabDfHx8fjwww+RmJiIF198EWfOnEFiYmKN27l//36cPn0a3bt3x0MPPYQmTZrYA993331X4/VWtH37dhw5cgT33XcffH19MWbMGJe73tPS0jBw4EDs378fjz/+OObMmYNBgwZh9erV9nl++eUX9OvXDxs2bMCkSZMwf/583Hnnnfjqq69q3L4NGzbgySefREJCAubPn28PrvPnz0evXr0we/ZsvPTSS/Dx8cE999yDNWvWOC0/a9YsjB8/Hnq9HrNnz8asWbMQHR2NDRs2AADGjx+Pc+fO4ZtvvnFaLisrCxs2bMD9999f47YTUQMhiIhq2X333SfCwsJEWVmZfdqZM2eEVqsVs2fPtk/r1q2baNmypSgoKLBP27hxowAgWrdubZ/26aefCgBi3rx59mlWq1XccsstAoBYunSpy3Z8/PHHAoD47rvvKt22atUqAUA0b95cdOjQQSxdulQsXbpUdOjQQfj6+oqff/655gUoJzk5WURHRwubzSaEEGL9+vUCgNi9e7d9nrKyMtGmTRvRunVrceHCBaflleWEEGLgwIEiICBAHD9+3O08iYmJTrVTzJw5U1T8CAAgtFqt2LdvX6X5i4uLna6bzWbRtWtXccstt9inHT58WGi1WjF69GhhtVpdtslqtYqWLVuKhIQEp9vnzp0rNBqN+OOPPyptm4iuLuz5JKJal5CQgJycHKezzD/55BPYbDYkJCQAAE6fPo1ff/0VEyZMgL+/v32+m266qdKJQuvWrYNer8ekSZPs07RaLaZMmVLjNhYWFgIACgoKkJ6ejokTJ2LixIn49ttvIYTAq6++WuN1K8rKyrBy5UokJCTYd3nfcsstCAsLc+r93L17N44ePYonnngCQUFBTutQlsvNzcXmzZvxwAMPoFWrVi7nqYmbbroJsbGxlab7+fnZ/79w4QLy8vJw4403YteuXfbpn3/+OWw2G2bMmAGt1vnjRWmTVqvFuHHj8OWXX6KgoMB++7Jly9C/f3+0adOmxm0nooaB4ZOIat1tt92Gpk2bYuXKlfZpK1euRM+ePdGxY0cAwPHjxwEA7du3r7R8xWnHjx9HixYtYDKZqpxPDSVcDRgwANHR0fbprVq1wg033ICtW7fWeN2K9evXIzc3F3379sWRI0dw5MgRHD16FIMGDcKHH34Im80GAPj9998BwH44git//PFHtfPUhLvwt3r1alx//fUwGo1o1qwZQkND8dZbbzmNAvD7779Dq9W6DK/lTZgwAZcuXcJnn30GQI5IkJGRgfHjx3vvjhDRFYvhk4hqncFgwJ133onPPvsMZWVlyMzMxA8//GDv9bwSREZGAgDCw8Mr3RYWFoYLFy5c9jaU3s17770XHTp0sF9WrlyJzMxMlydlXS53vaBWq9Xl9PI9nIrvv/8ed9xxB4xGIxYtWoS1a9ciLS0NY8eOhRBCdZtiY2PRu3dvfPDBBwDkCUq+vr649957Va+LiBoeDrVERHUiISEB//3vf5Geno4DBw5ACOEUPlu3bg0AOHLkSKVlK05r3bo1vvvuOxQXFzv1frpa1lPdunWDXq9HZmZmpdtOnz6N0NDQGq8bAIqKivDFF18gISEBd999d6XbH3vsMSxbtgyDBg1Cu3btAAB79+7F4MGDXa6vbdu29nmqEhwcjIsXL1aarvQ0e+LTTz+F0WjEN998A4PBYJ++dOlSp/natWsHm82G/fv3o2fPnlWuc8KECUhJScGZM2ewfPlyjBw5EsHBwR63iYgasHo+5pSIGgmz2SyaNWsmkpKSxPXXXy/69u1baZ6uXbt6dMLRJ5984vUTjoQQYtSoUUKn04kDBw7Yp+3fv1/odDrx6KOPqrvDFbz//vsCgNi8ebPL2ydNmiSCgoJESUmJsFqtXjvh6M033xQAnE6YOn36tPD393d5wtGUKVMqtS0lJUWYTCZRVFRkn3b06FFhMpmc1uHJCUeKnJwc4ePjI+655x4BQHz66acu60JEVx+NEDXYZ0JEVAOTJk3CihUrUFRUhNdeew0pKSlOt3/11VcYNWoUunXrhqSkJFy4cAFvvvkmIiMjUVhYiKNHjwKQu4z79++PjIwMPPLII+jcuTO+/PJL5OTkYM+ePXjvvfechl3617/+BQDYt28fVqxYgQceeMB+bONzzz1nn2///v3o168fAgIC8NhjjwEA3njjDZSVlWH37t2Iioqq8X0fPnw4du7ciezsbOh0ukq3r169GvHx8fj0008xZswYfPPNN4iPj0dkZCSSkpLQokULHDx4EPv27bMPU/Tzzz/jhhtugMFgwEMPPYQ2bdrg2LFjWLNmDfbs2QNAjofaunVrhIeH47HHHkNxcTHeeusthIaGYteuXU67zTUaDaZMmYI333zTqW0bNmzArbfeihtvvBFjx45FTk4OFi5ciIiICPzyyy9O65gxYwZeeOEF9O/fH2PGjIHBYMDOnTsRGRmJ1NRUp/XGx8dj9erVCAoKQlZWllOvKhFdxeo3+xJRY5KWliYACI1GI06ePOlynhUrVojOnTsLg8EgunbtKr788ktx1113ic6dOzvNl5ubK8aOHSsCAgJE06ZNxcSJE8UPP/wgAIgVK1Y4zQvA7aWijIwMMXjwYNGkSRMREBAgRo0aJX777bfLut/Z2dnCx8dHjB8/3u08xcXFwmQyidGjR9unbdmyRQwZMkQEBASIJk2aiO7du4sFCxY4Lbd3714xevRoERQUJIxGo+jUqZOYPn260zzr168XXbt2Fb6+vqJTp07igw8+cDvUkqueTyGEePfdd0WHDh2EwWAQnTt3FkuXLnW5DiGEWLJkiejVq5cwGAwiODhY3HTTTSItLa3SfB999JEAIB566CG3dSGiqw97PonoitezZ0+EhoYiLS2tyvk+//xzjB49Glu2bMGAAQPqqHVUU1988QXuvPNObN68GTfeeGN9N4eI6gjPdieiK4bFYkFZWZnTtI0bN+Lnn3/GzTff7DT90qVLTtetVisWLFiAwMBAXHvttbXdVPKCd955B23btsUNN9xQ300hojrEs92J6IqRmZmJwYMH4/7770dkZCQOHjyIxYsXIyIiApMnT3aa929/+xsuXbqEuLg4lJaWYtWqVdi6dSteeukll8MFeYPVakVubm6V8/j7+zsNkk+VrVixAr/88gvWrFmD+fPnX9ag+ETU8HC3OxFdMfLy8vDQQw/hhx9+QG5uLpo0aYJbb70VL7/8sn34IcXy5csxZ84cHDlyBCUlJWjfvj0eeeQRJCcn11r7jh07Vu0v8MycORPPP/98rbXhaqDRaODv74+EhAQsXrwYPj7sByFqTBg+iYg8VFJSgi1btlQ5T9u2be1jcBIRUWUMn0RERERUZxrEvg6bzYbTp08jICCAxwYRERERXYGEECgoKEBkZCS0WvfntDeI8Hn69GlER0fXdzOIiIiIqBonT55Ey5Yt3d7eIMJnQEAAAHlnAgMDvb5+i8WC9evXY+jQodDr9V5f/9WG9fIca6UO66UO6+U51kod1ksd1kvKz89HdHS0Pbe50yDCp7KrPTAwsNbCp8lkQmBgYKN+0niK9fIca6UO66UO6+U51kod1ksd1stZdYdIcpB5IiIiIqozDJ9EREREVGcYPomIiIiozjB8EhEREVGdYfgkIiIiojrD8ElEREREdYbhk4iIiIjqDMMnEREREdUZ1eFz8+bNiI+PR2RkJDQaDT7//PNql9m4cSOuvfZaGAwGtG/fHu+9914NmkpEREREDZ3q8FlUVIQePXpg4cKFHs1/9OhRjBw5EoMGDcKePXvwxBNP4K9//Su++eYb1Y0lIiIiooZN9c9rDh8+HMOHD/d4/sWLF6NNmzaYM2cOAOCaa67Bli1b8Prrr2PYsGEulyktLUVpaan9en5+PgD581UWi0Vtk6ulrLM21n01aoz1KikBTp8GMjM1yMwEbDagbVugbVuB0FCg/C+JlZUBly7JZQoKynDmjAnHj5chMBDw8wP0eqC0VN5eWiqXNZnkxcdHTsvNlZezZzVOfy9dAsLCgMhIgagooGlTgZISDS5dcmxT/tWgpESu28cH8PER0OkAnU5eV/7q9Y6LEOWXh9N6zWagWTMgPFygRQsgOFhut7AQKCyU9QgLA0JDBcLD5boLCmC/XasFDAbAaJS35ecDFy9qcP68nM9slnUrKbHh0KFWKCmxISSkDEFBAmVl8v6fPQtcuKCB1Vqzx1AIoKhIbjs/Hygs1MDXFzCZBEwmwNdXzmezyXmFkP8ry5pMQHi4vI+hofJ+2GzyUloKnDkDnD6twenTwPnzmgq1Fk51r/i3/P9aLWC1yktZmbwo/1utch5/fyAgADAabdi/PxqZmTYIYXVapvxyFdeh/O/rCzRpItfXpIm8L2az88VikX91OqBVK6B1a4HWrQU0GuD4cQ2OH9fgxAk5j3I/XN1PnU7eN51OznvhgnwOXLgg21L+uSgvwv6/TueYDsjnTF6eBnl5svaePf4a5Ob2xTvvaKDRyAdWq3W89kwmeZ/KyuR9tlg0f/6VF6tVbt9olM9lvV7AatVUqrNyXadzPOcNBgGDAfaLXu94rRUXA2Zz1T9FGBQkEBkpX/dhYUBOjlJ7IDtbPo+VdRuNztu6dAk4f16+hi5ccDx//P3lfS4t1aC4WLZDeRyMRkCv1+Ds2Z74+mvAz89q34bj/gMXL8q25ORocPEi7DXVauV7j/K/q+sVb7PZZN1c/S3/mnR1CQwEQkIEmjUDmjZ1vM7z8uR7mOO9TgCQ9a74PFee63q9o3a+vs7vBRW3q9M51+PEiR746CMNyspsldZdVuZ4/lf8q9HIzwb5uhbw85OPW36+fI4XFzue/76+jovBIODr63gPKi3V2D9XzGbHZ8yddwo88YRNxbtlzXmaC2r9t923bduGwYMHO00bNmwYnnjiCbfLpKamYtasWZWmr1+/HiaTydtNtEtLS6u1dV+NKtbLagUKCgwoKPCF1ar5801DAyE0f/6V18tPkx92OpjNOpSW6mA2a6HX2+DjY4Ovrw1CAAUFvigo8EV+vi9KS3X2dVRcp82mwaVLPigu1qOoSI+yMg2CgkrRrFkJmjcvQZMmFpjNWlgscjvKdiv+b7HItlgsjullZe53EhiNZfD1tdqXt9nKz6sHMMTjmup0NlitjflQbB8AvbBgQX23o6HQAbi2vhvRQGgBtKjvRjQgWgCt8e239d2OhkILIKa+G+FSYOBRdOz4S51sq7i42KP5aj18ZmVlITw83GlaeHg48vPzcenSJfj5+VVaZtq0aUhJSbFfz8/PR3R0NIYOHYrAwECvt9FisSAtLQ1DhgyBXvlq3UhZLEBWluyVKP/tTPZKyW/IeXllSEs7CKOxC44f1+HYMeDMGQ1ycgCrtepv8HUtJ6eJ19bl5yd7GyMj5bfno0c1OHUKKCnxQUmJ65eSwSCg0VhhtepgsVSujUYjIIRjuhI8fXwEQkKAkBDZ06b89fOTPR1KL2xhofzGbDDI9vn5yW/iyrdxuc7KPV5K7478K3tv5LdvAaMRTuuRvbUC585pkJ0NZGXJHkuTSelBkfU4e1befumS4/74+Qk0aeLoVS0tBcrKNAgIEAgOBoKCZO+tr6/SQ2ZDVtY56HQhuHhRiwsX5P1o1kz2bAQHO3q/asJkktsLDJRtt1hkr4LS26v0zmg0lS8FBbKHR/ZKyy9OymvExweIiHD0ToWEyN4Id71i5R8TOV3jdFv5HlGl11rpQSwrk722BQVAQYHA2bO5iIgIgV6vddmT6qrXVbmYzbKXqLBQPpd0uvI9K8L+v14v51V6244fl4+x7AUFWrWSz73y98G511Xj1Jvl4yN7z4OCYH9MHT2OlS9Wq+N/QPb6Nm0qL/I1Vv1jb7VasX//fsTGxkKn0wGQdVd6H4uK5PO0cg+s0vsqYLFo7HstLJbKvdeO+grYbI5eqIq9URaLxv5aU3rd3d0HIYBz5+Tr/fRp+RwMD3fUvUULWbvy2yl/8fWF/b0kOFjAanU83sXFsLfBZJLPM4tF9qAVFVmxb98RREd3+POLuLJ+eb/MZvnYhYbK3tjgYPk4lO8pdFw09p5D5+mOi6seQflXVHpdAo7rQsgewrNnZQ9vXp4G/v7C/hxRnpfK+50Qzj2bvr7C3qPo4+Po6S8tlY91+e06/pdtslodz4dLl6w4evR3XHNNO/j56ew9k8q6dTrn+1u+V9dqlZ+vyt4i5XFRnuMmk/izd7Nyj62y96x8r3TF3va2bVuiR4+WNX/jVEHZU12dWg+fNWEwGGBQPjnL0ev1tRoOa3v9tU15o6nqjVgI+QI9fhz47Tfg0CHg4EHgyBHg1CkgO1vOUzUfAD1d3qLRyECh17vfxVDxr+PNT75Q5JuffEELATRv7njz9Pevel3KG05goKxFVhaQmSkv+fmOMKWEq4r/u7u9SRMgKEjzZ20dBS4pkbW0WCovZzAAVmsZ1q5dixEjRgDQ23dhK28SPj4a+2On7Ppy3pbz9qrmjeBfk3U4L1NYKN9M5WNVeX1CABqnJ6njf4vFirVrf8SIESOg1+u80La6VPfts1gsWLt2+5/1qo8e8yv9MXGwWATWrj2BESO6Qq+/Ij/6VKj9ulssNqxdexgjRnRw8VqkimS9fsOIEe0bdb08zVC1/gqMiIhAdna207Ts7GwEBga67PUkdWw2YPVq4KWXgO3bZegLDpaX8kFNq5Xfnk+ckL08VfHxkT1NQji+nWm1MhSZTLI3S6fLxvXXh6J9ex3atgWiooAWLYDQ0MvrmWpojEagUyf3t5c/PrH8MWuu1mM0yro3dP7+Vd/uSS8VERFdvWo9fMbFxWHt2rVO09LS0hAXF1fbm76qFRcDX34pQ+evvzqmWyzKAeBVLx8WBnToIINTp05Ax47yZIKoKBkgtVV0olgsZeV6WxrvNzwiuoKcPw9s2SJ3f/TtK78t15eiIrn7o6o3UvKMxSJ3W5lM8hs6v71WrahI9jQpu9KKi+WZkh061HfLnKgOn4WFhThy5Ij9+tGjR7Fnzx40a9YMrVq1wrRp05CZmYn//e9/AIDJkyfjzTffxNSpU/HAAw9gw4YN+Oijj7BmzRrv3YtGQAjg+++BtDRg40bZy1n++KcpU4BHHpGvywsX5PtwcbHzWYPBwUB0NNCypXwNUzlHjzpOZ66OxSKL6uLQkAarpETep4on9Nls8pvMqVPK6ffyUlQku7pbtZKX6OjKy9bE7t2I2rwZmrIyeeyE41RkpdtdducrzGbZtpMnZbe+zQYMGwZ07uz5h1RZGfDLL8DvvzvuU2SkvO2PP+SxKYcPy+EN7rijbgNFcTGwZ4/zB4lykGpxMbQFBYjduxfa9euVIQqcj5vR6+U3SuUxCg8vvwvDuSu+rEy+Dg4elPf59GmgdWv57bRzZ/kN1VWgu3BBhj6bzXGMTHCwXJ/SXrPZcVyKySRrqAylUFzsODCxeXPYT9/Ny5PPtXPnHM+7c+dgP9BZeU78/rt8Y/zpJ8d91+mAXr2A/v2BiAjAZILG1xfRhw5Bo5zyXZEyHIKyrfPnnU+H9/cHrrlGrrd9e3lbTg6wdSvwww/A/v3yOXjypGx7ixbA5MnAQw/JNpRXVgb8/LNc7ocf5LE75Y8/Uh4f5f+gIEd9mjaV21We83l58rmp9CQ0bSpfE0pbyv/NzHQeXqPitkJCgJtuAgYPltuqSkGBDIXKY2ixyMe9eXP52q3u9ae8dk+ckMdH6fWOdhQVOeq6Y4fz7jqlndHRzs9r5bnn7y+HnjhxQl7y852P3YqKknVq08bxPMjPl8/5I0dkbZXnmnIKv8LXV65LWV9EhOM90N8fPkVF0OzcKddz/Li8T+WPKStfkyZNHO2vOGRKeVarbM/Jk47H0ccHuOsu5+fV2bOyN2rRospDQPztb8Abb1T9eNQxjRDVH+FX3saNGzFo0KBK0xMTE/Hee+9h4sSJOHbsGDZu3Oi0zJNPPon9+/ejZcuWmD59OiZOnOjxNvPz89G0aVPk5eXV2glHynF5V9oxn0IA6enAc8/JwFley5bApEnyeRUcXHdt8nq9yr/pX7woX6Qmk3xxVnzBKmP1eIMQwNdfA6++CmzaJKdFRsoPl27d5HaVD88LFxwv/jNn5G0xMY43/HbtHG8kERHyA3H3bth++gkXdu5EcEQEtMqHfng4cNttwC23VP8toKDA8SZ68qS8Hhsr2xgRIe/D/v2ObyX+/kB8PDB8uPwAsNnkm/cXX8g38vLDYJSWOj7YlTMU/fzkm2qzZnJbp07JDwlPNG/u+EBQxgqpGJqUb0T9+wOjRgEjRsg2f/IJsGBB5Sd5TXXoIINiu3aOx+3UKflhoHxw+PkBu3bJbRYWOi+vHKtSVuY8PTYWmDkTuPtueds33wArVgCbNzvf/+BgGV6U+prNzh/2nTvLD/jrrnP/fN64ERg3TobAK4FGIwNor17ykp/vCH3KmFTe4O8vnzs1GVOrc2f5WJ465b32uOLvLwPD0aPVz6vXA2PGyACphIc//nC85q5QomtXnIiIQMtevaALD5fvCadOydfM7t0yXLnj4yO/uIwYIV/nAwfK58h338lddl9/LZdXFz+8S6+XoT0/X76nXyZhMEDj6bhfFRmN8j2jfFDNz8ef48u5rpNOJ+v7wAPyM+CVV+QygGMMNWV9Y8cCzz9f4/umhqd5TXX4rA+NLXxaLPJ1eeAAMHeu/AwC5GflmDHAoEHAzTfL181l74GwWoFt2+QHSGio41tcZKTbAxQtFgvWrlmDEa1aQb92rez1aNrUEb4CA+U3v0OH5EWnA0aPBu67T4YCIeT2PvxQvhGdOuX5YH0GA9C9u/zw69lT9vQoZ0398YdzuPLzk8UaNUp+0JtMcv5ff5WBbPFiYO9eOa9yKmJdvhz8/WUv3fXXO94oDAYZXJU3+Ko+3CIi5BPA1RunXi8D3sGD8iyyy6HVym2Fhzt6D0wmGYqUYFxQULN163Ty+XLhAgBA6PU43749ggMCoC0pqRxcKwZhjUa2TQl9BQXyA87TwKwIDJTBUunlVZY3mWTgattWfgvMy5PTO3SQPcEVe0bUatpUPkdHjpRfGsLDZaidPRv417/k8zEkRL4eK/aGmUywGo04mpWFNrGx0MmBP517Zi9dcu4ZPnvW8aXA1cHfLVrIANepk+whOnbM8TrOzXV/Pzp1kuFKCdsXL8rHVnleKwNbKo+jEI774ufn+CJUMcQGBDi+LJTv2Sq/rmbNgFtvla/xqCi53IkT8svWzp3yMbt0CbbCQpw9eRIhoaHQunvj9POT74PNmzsOwC7/BfTXX2WPZUmJY5kuXYABA4DevfHnKejyObluHfDmm7IHz91jHxcnl+3SxTH0QsUe7qIiue3ytVXeq5X3299/d7wPFhbK6eV7BpW/LVvK54erL4WXLsn30G+/le8/nij/GOt0sp2uQnVQkDIWn/N0o1G2KzJS3q60RauVX8wGDABuuEG+3pTHvKhIvqcpX8hPnnTslTl3TgawFi0c97tpU9mus2flfMrZthWf/xER8rXeooXjfa5pU+fXU0mJc0/86dNy++WOcxMtWkDTubN8z7DZnIfTKC8vz9GZUd3njkbjfJ9OnZKf2xX17Am8/DIwdGi9HZ7A8KlCfYdPIWTHyZIlctf6iRPydTgU38AXZmzQ34YHJ+vxz39W3nsDwPHGbbXKN5fqnnRWK7B2LfDZZ/JsJVcfKlqt85M9KMi+XltJCS6tW4cmNQk1114rX3S//175NoNBbsdsdv1ivRx+frKn8rffnHtUAgKAhx8GHn9cbvuXX+Qb78GDzrtMAgJkbZVwLoTjzf7gQfkhrbwRZmfLeXv1grV7d+wqLUWvHj3gYzbLN6J9+4CvvpK7wDwRFOS8a/vXX+W2lZeu0Sh7FgYPlm+IX3whb1cEBsqe0OHD5boUPj6ON9mQEPn4ln9jDQhwfDBU97rIy3PevVdaWnnXnnIpKZEfzF984ThgOSoKmDwZlokTsTYjw/1r0Wp1fqPWaJx3wwPyA27dOvncvnjR8Rxu2dKxC+vcOdnm2FjHh7+yHuVQA4tFtkv58Ll4Ue66mjvXEUJbtAASEmQva2mpI4xfvOgcmnx9HbuZ8/Nlb2t6uj102+/L9dfL7Ss9wA88ILfp5vjFy3rvUsZ5Ka+qvQrZ2fILkXLx9ZWhb8gQWduK63Z3eIIyFk/F2202WTdlHK/mzb16aIvX3ufLyuTrKytLfgmu7izBXbuAlSsdQUuO1C8DlbcP4VBeG5cbPHJzUbZ+PQ6vWYOOzZtDp/Tih4bK+3zttTLolH8/UVy6JF9ju3fL1/hXXzk+Y1q0kF+yRo2S4VJ536lrNpsMcIcPy/fHjh1l0KypkhJYjh/H+l27MPTuu9U9v8xm+Vnw55cke1iVI+c7vghVXOeBA8DSpcDy5fK9evp04C9/qffjjBk+Vaiv8Jl3UeDdORex6MNgpyymhRVzdE/jCav8VShrSBh0EycAEyfKD27lOKGffpIfkuV3GYaHyx6vAQNkILn2WseHqrKb+ZlnnM9SCgqS8+bnOwKEB79SIIxGaAYPlruQzWbnY5DatXPsks7Nlb2c337rCH4mk/zATkiQb2ZKb1r5NyKr1bkHSwj5TVPpFfzlF7mMckxahw4yZCqysmQA+eIL2S6F8gY6eLA8bsHVG+jlUAZqRBXPLSGAjAzZ83v0qNNxfEpwtffuuvpwKyqSPTAWC9CvX+Xd94cOyS7zNm1kN7ny8z1XmqNH5YfA9dcDen29fxH0yMWL8nGLjpavm4rh11NWq3wur1sn1/fTT47bAgKAt9+Wewuq0CDqdYVgrdTxWr2sVvnc1unk59FVehIWn1+Sp3mtoQ921mDl55Tgp47jkJK3Ch0xEq+ZZqLjuOswblQh+r4xDn7rv5QzNm8O3dkc4LXX5MUd5Ri17GzZo/nZZ3J6cLA8tnDgQGDVKsexjUFBwPjxjuNxyr9YlJ6f8j1Z5XaXWG02ZJSWotfTT0PvaXBLTJQhdPVq2YszcmT1Z6PqdM5hEpAH+rdvD9x7b/Xb7N5d7n6YP18G1TNn5LGckZG1+23bkzCi0QB9+shLTTRpIr9kuKME/ytdmzby0pAEBQETJlz+enQ62ftz3XWy1yIzU/YSnTwpezzbtbv8bRDVN51OfkEmKofhs7adOiV758r1XpXm5uNopztwa54MgrdjDW4vXgOcHgk8lynPbjUYgPfek2e0rV0r98mvWSOPd1J6NuPiZO9L8+aO3dU//eToGd28We7W+/RTeQHkeh97TPZ+uttdpBzjFxEhhyypwGax4MzateildiiT0FAgKUndMt6g0QA9esgL0ZXqz0MPiIiudgyfteXgQeCf/5Q9kAaDPBYjORm2lq2QGTscPS7uQj4CcPZfi9H28Hrg/fdluATkIJxffCF3RQKyd3LUKLnL3dfX/W4Lo1EenH3DDfJ6WZk84D4tTR5M2q4d8OyzMrASERER1QOGT287fhx48UXg3XcdB/OXlgL//S/w3//CrPdHW0shchCKPxauw/WPXgtgrAyFL78sdw0vWiRPjqlI7eCcPj6yd5QD+hMREdEVguHzclkscqy/tDR5OXDAcdudd8pBX/PzYZ3/JsTKlTBaCnEcrfDrnDTc/mhHx7wdOsjASkRERHQVY/i8HFarHL4mPd0xTauVvxDxr3/ZTwjJzATuPtoPf9hew3Csw40v3oYHUzz4JR0iIiKiqwzD5+V4/XUZPJs0Ae6/X453d8stTj83tHkzcM898uTxoKBwJCxPxPDh9dhmIiIionrE8FlTe/fK4zQBOZTPgw9WmmXHDjkGc1mZHPVn1SqOnkJERESN29U52mttM5vlOH9msxyv8oEHKs1SWipHFSorA26/Xf4SFoMnERERNXYMnzXxr3/JX9hp1gx45x2XA5a/8AKwf78cNem99+RQn0RERESNHcOnWj/9JM9gB4C33pK/VVvB7t1y1CRAjprUvHkdto+IiIjoCsbwqdbMmfIs94QElz/xaDbL3e1WqzzR6K676qGNRERERFcohk81jh4Fvv5a/v/CCy5neeUV4OefZW/nm2/WYduIiIiIGgCGTzXefhsQAhg6VA4KX0FOjvxxIwBYsEAe70lEREREDgyfniotdfwC0SOPuJzlnXfkbNddJ3/KnYiIiIicMXx66pNPgLNngZYt5dhJFVgs8vwjAHjsMZcnwBMRERE1egyfnlq0SP59+GHAp/LY/J9/Ln9GMyxMnmhERERERJUxfHri55+BrVtl6PzrX13O8sYb8u/DDwMGQx22jYiIiKgBYfj0hLI/fcwYICKi0s179gBbtshsOnly3TaNiIiIqCFh+KxOXh7wwQfyfzcnGi1YIP/edRcQGVlH7SIiIiJqgBg+q7NuHVBUBHTqBNx0U6Wbz50Dli+X///tb3XcNiIiIqIGhuGzOqdOyb+9e7s8hf3//g8oKQF69QL696/jthERERE1MAyf1cnKkn9dHOsJOPbIJydzeCUiIiKi6jB8VqeK8JmbC+zdK/+/4446bBMRERFRA8XwWZ0qwufmzfJvt25ASEgdtomIiIiogWL4rE4V4XPjRvn35pvrrDVEREREDRrDZ3U8CJ8uToInIiIiIhcYPqtiscjfcwcqhc/yx3sOHFjH7SIiIiJqoGoUPhcuXIiYmBgYjUb069cPO3bscDuvxWLB7Nmz0a5dOxiNRvTo0QPr1q2rcYPrVE6O/KvTAc2bO92kHO/ZtSsQGlrH7SIiIiJqoFSHz5UrVyIlJQUzZ87Erl270KNHDwwbNgw5SlCr4LnnnsPbb7+NBQsWYP/+/Zg8eTJGjx6N3bt3X3bja52yyz08HNA6l2rTJvmXx3sSEREReU51+Jw7dy4mTZqEpKQkxMbGYvHixTCZTFiyZInL+d9//33885//xIgRI9C2bVs88sgjGDFiBObMmXPZja91PNmIiIiIyKt81MxsNpuRkZGBadOm2adptVoMHjwY27Ztc7lMaWkpjEaj0zQ/Pz9s2bLF7XZKS0tRWlpqv56fnw9A7sK3WCxqmuwRZZ0V163JzIQPAFtYGKzlbjt7Fvj1Vz0AIC7Oglpo0hXNXb2oMtZKHdZLHdbLc6yVOqyXOqyX5On9VxU+z549C6vVivDwcKfp4eHhOHjwoMtlhg0bhrlz52LgwIFo164d0tPTsWrVKlitVrfbSU1NxaxZsypNX79+PUwmk5omq5KWluZ0vePmzbgGwEmLBXvWrrVP37atBYC+aNUqHzt3fldr7bnSVawXucdaqcN6qcN6eY61Uof1Uqex16u4uNij+VSFz5qYP38+Jk2ahM6dO0Oj0aBdu3ZISkpyu5seAKZNm4aUlBT79fz8fERHR2Po0KEIDAz0ehstFgvS0tIwZMgQ6PV6+3Tt+vUAgJa9eyNyxAj79LQ0ebTCyJFNMKLc9MbCXb2oMtZKHdZLHdbLc6yVOqyXOqyXpOypro6q8BkSEgKdTofs7Gyn6dnZ2Yhw89vnoaGh+Pzzz1FSUoJz584hMjISzzzzDNq2bet2OwaDAQaDodJ0vV5fqw9qpfXn5gIAdFFR0JWbrpzpfsstOuj1ulprz5Wuth+PqwlrpQ7rpQ7r5TnWSh3WS53GXi9P77uqE458fX3Ru3dvpKen26fZbDakp6cjLi6uymWNRiOioqJQVlaGTz/9FKNGjVKz6frh4oQjebyn/J/jexIRERGpo3q3e0pKChITE9GnTx/07dsX8+bNQ1FREZKSkgAAEyZMQFRUFFJTUwEA27dvR2ZmJnr27InMzEw8//zzsNlsmDp1qnfvSW1wET6//17+jY0FwsLqoU1EREREDZjq8JmQkIDc3FzMmDEDWVlZ6NmzJ9atW2c/CenEiRPQlhsTs6SkBM899xz++OMP+Pv7Y8SIEXj//fcRFBTktTtRa1yEz61b5V/+pCYRERGRejU64Sg5ORnJyckub9uoDID5p5tuugn79++vyWbqV1ERUFAg/y8XPjMz5d8OHeqhTUREREQNHH/b3R3lpCo/PyAgwD5Z+SEn7nInIiIiUo/h053yu9w1Gvtkhk8iIiKimmP4dMfNT2syfBIRERHVHMOnOy7Cp81mH/qT4ZOIiIioBhg+3XERPs+flwEUAEJD66FNRERERA0cw6c7LsKncg5S8+aAT63/MCkRERHR1Yfh0x0X4ZPHexIRERFdHoZPdxg+iYiIiLyO4dMdZR87wycRERGR1zB8uiKEo+fzz58NBRg+iYiIiC4Xw6crFy8CZrP8n+GTiIiIyGsYPl1Rej2DggCj0T6Z4ZOIiIjo8jB8usJfNyIiIiKqFQyfrjB8EhEREdUKhk9XGD6JiIiIagXDpysuwmdJCZCfL/9n+CQiIiKqGYZPV6oYYF6vB5o2rYc2EREREV0FGD5dqebXjTSaemgTERER0VWA4dOVKsJnuWE/iYiIiEglhk9X+LvuRERERLWC4bOisjIgN1f+z/BJRERE5FUMnxWdPSt/212rBUJC7JMZPomIiIguH8NnRdnZ8m9YGKDT2SczfBIRERFdPp/6bsAVp0cPoLgYuHDBaTLDJxEREdHlY/h0xc9PXsph+CQiIiK6fNzt7iGGTyIiIqLLx/DpASEYPomIiIi8geHTA3l5gMUi/w8Nrd+2EBERETVkDJ8eUE6ADwwEjMb6bQsRERFRQ8bw6QHuciciIiLyDoZPDzB8EhEREXlHjcLnwoULERMTA6PRiH79+mHHjh1Vzj9v3jx06tQJfn5+iI6OxpNPPomSkpIaNbg+MHwSEREReYfq8Lly5UqkpKRg5syZ2LVrF3r06IFhw4YhR0loFSxfvhzPPPMMZs6ciQMHDuDdd9/FypUr8c9//vOyG19XGD6JiIiIvEN1+Jw7dy4mTZqEpKQkxMbGYvHixTCZTFiyZInL+bdu3YoBAwZg7NixiImJwdChQ3HfffdV21t6JVHCZ3h4/baDiIiIqKFT9QtHZrMZGRkZmDZtmn2aVqvF4MGDsW3bNpfL9O/fHx988AF27NiBvn374o8//sDatWsxfvx4t9spLS1FaWmp/Xp+fj4AwGKxwKKMeeRFyjrdrTsrSwdAi+bNrbBYbF7ffkNTXb3IgbVSh/VSh/XyHGulDuulDusleXr/VYXPs2fPwmq1IrxCF2B4eDgOHjzocpmxY8fi7NmzuOGGGyCEQFlZGSZPnlzlbvfU1FTMmjWr0vT169fDZDKpabIqaWlpLqcfOjQAQAhOndqFtWtP19r2Gxp39aLKWCt1WC91WC/PsVbqsF7qNPZ6FRcXezRfrf+2+8aNG/HSSy9h0aJF6NevH44cOYLHH38cL7zwAqZPn+5ymWnTpiElJcV+PT8/H9HR0Rg6dCgCAwO93kaLxYK0tDQMGTIEer2+0u1PPy3LNGxYL9x0U0+vb7+hqa5e5MBaqcN6qcN6eY61Uof1Uof1kpQ91dVRFT5DQkKg0+mQrYy6/qfs7GxERES4XGb69OkYP348/vrXvwIAunXrhqKiIjz00EN49tlnodVWPuzUYDDAYDBUmq7X62v1QXW3/txc+Tcy0geN+DlVSW0/HlcT1kod1ksd1stzrJU6rJc6jb1ent53VScc+fr6onfv3khPT7dPs9lsSE9PR1xcnMtliouLKwVMnU4HABBCqNl8vbBYgPPn5f88252IiIjo8qje7Z6SkoLExET06dMHffv2xbx581BUVISkpCQAwIQJExAVFYXU1FQAQHx8PObOnYtevXrZd7tPnz4d8fHx9hB6JTt7Vv7VaoFmzeq3LUREREQNnerwmZCQgNzcXMyYMQNZWVno2bMn1q1bZz8J6cSJE049nc899xw0Gg2ee+45ZGZmIjQ0FPHx8XjxxRe9dy9qkXKEQWioDKBEREREVHM1OuEoOTkZycnJLm/buHGj8wZ8fDBz5kzMnDmzJpuqdxxgnoiIiMh72JdXDWW3e0hI/baDiIiI6GrA8FkNZax7P7/6bQcRERHR1YDhsxrKYP2NeOQEIiIiIq9h+KwGwycRERGR9zB8VsNsln8ZPomIiIguH8NnNdjzSUREROQ9DJ/VYPgkIiIi8h6Gz2owfBIRERF5D8NnNZTw6etbv+0gIiIiuhowfFaDPZ9ERERE3sPwWQ2GTyIiIiLvYfisBsMnERERkfcwfFaD43wSEREReQ/DZzXY80lERETkPQyf1WD4JCIiIvIehs9qMHwSEREReQ/DZzU4zicRERGR9zB8VoM9n0RERETew/BZDYZPIiIiIu9h+KwGwycRERGR9zB8VoPjfBIRERF5D8NnNdjzSUREROQ9DJ/VYPgkIiIi8h6Gz2owfBIRERF5D8NnNTjOJxEREZH3MHxWgz2fRERERN7D8FkNhk8iIiIi72H4rAaHWiIiIiLyHobParDnk4iIiMh7GD6rwfBJRERE5D0Mn9Vg+CQiIiLynhqFz4ULFyImJgZGoxH9+vXDjh073M578803Q6PRVLqMHDmyxo2uSwyfRERERN6jOnyuXLkSKSkpmDlzJnbt2oUePXpg2LBhyMnJcTn/qlWrcObMGftl79690Ol0uOeeey678bVNCKCsTP7PcT6JiIiILp/q8Dl37lxMmjQJSUlJiI2NxeLFi2EymbBkyRKX8zdr1gwRERH2S1paGkwmU4MIn0rwBNjzSUREROQNPmpmNpvNyMjIwLRp0+zTtFotBg8ejG3btnm0jnfffRd/+ctf0KRJE7fzlJaWorS01H49Pz8fAGCxWGBR9oN7kbLOiusuLgYAJXVaUAubbpDc1YsqY63UYb3UYb08x1qpw3qpw3pJnt5/jRBCeLrS06dPIyoqClu3bkVcXJx9+tSpU7Fp0yZs3769yuV37NiBfv36Yfv27ejbt6/b+Z5//nnMmjWr0vTly5fDZDJ52tzLVljog/vvl8emfvzxV9DrbXW2bSIiIqKGpLi4GGPHjkVeXh4CAwPdzqeq5/Nyvfvuu+jWrVuVwRMApk2bhpSUFPv1/Px8REdHY+jQoVXemZqyWCxIS0vDkCFDoC+3fz031zFPfPxt0HJsAADu60WVsVbqsF7qsF6eY63UYb3UYb0kZU91dVSFz5CQEOh0OmRnZztNz87ORkRERJXLFhUVYcWKFZg9e3a12zEYDDAYDJWm6/X6Wn1Q3a1fqwUMhsb7ZHKnth+PqwlrpQ7rpQ7r5TnWSh3WS53GXi9P77uqvjxfX1/07t0b6enp9mk2mw3p6elOu+Fd+fjjj1FaWor7779fzSbrFYdZIiIiIvIu1bvdU1JSkJiYiD59+qBv376YN28eioqKkJSUBACYMGECoqKikJqa6rTcu+++izvvvBPNmzf3TsvrgBI+OcwSERERkXeoDp8JCQnIzc3FjBkzkJWVhZ49e2LdunUIDw8HAJw4cQLaCgdHHjp0CFu2bMH69eu90+o6wp5PIiIiIu+q0QlHycnJSE5Odnnbxo0bK03r1KkTVJxUf8Vg+CQiIiLyLp6/XQWzWf5l+CQiIiLyDobPKrDnk4iIiMi7GD6rwPBJRERE5F0Mn1Vg+CQiIiLyLobPKjB8EhEREXkXw2cVOM4nERERkXcxfFaBPZ9ERERE3sXwWQWGTyIiIiLvYvisAsf5JCIiIvIuhs8qsOeTiIiIyLsYPqvA8ElERETkXQyfVWD4JCIiIvIuhs8qMHwSEREReRfDZxU4zicRERGRdzF8VoE9n0RERETexfBZBYZPIiIiIu9i+KwCx/kkIiIi8i6Gzyqw55OIiIjIuxg+q8DwSURERORdDJ9VYPgkIiIi8i6GzyowfBIRERF5F8NnFTjOJxEREZF3MXxWgT2fRERERN7F8FkFDrVERERE5F0Mn1VgzycRERGRdzF8VoHhk4iIiMi7GD6rwPBJRERE5F0Mn1Vg+CQiIiLyLobPKjB8EhEREXkXw2cVOM4nERERkXcxfFaBPZ9ERERE3lWj8Llw4ULExMTAaDSiX79+2LFjR5XzX7x4EVOmTEGLFi1gMBjQsWNHrF27tkYNrksc55OIiIjIu3zULrBy5UqkpKRg8eLF6NevH+bNm4dhw4bh0KFDCAsLqzS/2WzGkCFDEBYWhk8++QRRUVE4fvw4goKCvNH+WsWeTyIiIiLvUh0+586di0mTJiEpKQkAsHjxYqxZswZLlizBM888U2n+JUuW4Pz589i6dSv0f6a4mJiYy2t1HWH4JCIiIvIuVeHTbDYjIyMD06ZNs0/TarUYPHgwtm3b5nKZL7/8EnFxcZgyZQq++OILhIaGYuzYsXj66aeh0+lcLlNaWorS0lL79fz8fACAxWKBRUmEXqSss+K6LRYfABpoNGWwWITXt9tQuasXVcZaqcN6qcN6eY61Uof1Uof1kjy9/6rC59mzZ2G1WhEeHu40PTw8HAcPHnS5zB9//IENGzZg3LhxWLt2LY4cOYJHH30UFosFM2fOdLlMamoqZs2aVWn6+vXrYTKZ1DRZlbS0NKfrhYXDABjx44/fIycnv9a221BVrBe5x1qpw3qpw3p5jrVSh/VSp7HXq7i42KP5VO92V8tmsyEsLAz/+c9/oNPp0Lt3b2RmZuLf//632/A5bdo0pKSk2K/n5+cjOjoaQ4cORWBgoNfbaLFYkJaWhiFDhtgPDQAArVaW55ZbbkBsrNc322C5qxdVxlqpw3qpw3p5jrVSh/VSh/WSlD3V1VEVPkNCQqDT6ZCdne00PTs7GxERES6XadGiBfR6vdMu9muuuQZZWVkwm83wdTGIpsFggMFgqDRdr9fX6oNacf1K77HJpOdxny7U9uNxNWGt1GG91GG9PMdaqcN6qdPY6+XpfVc11JKvry969+6N9PR0+zSbzYb09HTExcW5XGbAgAE4cuQIbDabfdpvv/2GFi1auAyeVxIOtURERETkXarH+UxJScE777yD//73vzhw4AAeeeQRFBUV2c9+nzBhgtMJSY888gjOnz+Pxx9/HL/99hvWrFmDl156CVOmTPHevaglPNudiIiIyLtUH/OZkJCA3NxczJgxA1lZWejZsyfWrVtnPwnpxIkT0GodmTY6OhrffPMNnnzySXTv3h1RUVF4/PHH8fTTT3vvXtQCIQCrVf7P8ElERETkHTU64Sg5ORnJyckub9u4cWOlaXFxcfjxxx9rsql6U360AIZPIiIiIu/gb7u7wfBJRERE5H0Mn24wfBIRERF5H8OnGwyfRERERN7H8OmGEj51OkDLKhERERF5BWOVGxzjk4iIiMj7GD7d4BifRERERN7H8OkGwycRERGR9zF8usHwSUREROR9DJ9uMHwSEREReR/DpxsMn0RERETex/DphhI+fX3rtx1EREREVxOGTzfY80lERETkfQyfbnCcTyIiIiLvY/h0gz2fRERERN7H8OkGwycRERGR9zF8usHwSUREROR9DJ9uMHwSEREReR/DpxsMn0RERETex/DpBsf5JCIiIvI+hk83ONQSERERkfcxfLrB3e5ERERE3sfw6QbDJxEREZH3MXy6wfBJRERE5H0Mn24wfBIRERF5H8OnGwyfRERERN7H8OkGwycRERGR9zF8usFxPomIiIi8j+HTDY7zSUREROR9DJ9ucLc7ERERkfcxfLrB8ElERETkfQyfbjB8EhEREXlfjcLnwoULERMTA6PRiH79+mHHjh1u533vvfeg0WicLkajscYNrisMn0RERETepzp8rly5EikpKZg5cyZ27dqFHj16YNiwYcjJyXG7TGBgIM6cOWO/HD9+/LIaXRcYPomIiIi8T3X4nDt3LiZNmoSkpCTExsZi8eLFMJlMWLJkidtlNBoNIiIi7Jfw8PDLanRd4FBLRERERN7no2Zms9mMjIwMTJs2zT5Nq9Vi8ODB2LZtm9vlCgsL0bp1a9hsNlx77bV46aWX0KVLF7fzl5aWorS01H49Pz8fAGCxWGBRUqEXKessv+7SUh0ALTSaMlgswuvbbMhc1YtcY63UYb3UYb08x1qpw3qpw3pJnt5/jRDC42R1+vRpREVFYevWrYiLi7NPnzp1KjZt2oTt27dXWmbbtm04fPgwunfvjry8PLz22mvYvHkz9u3bh5YtW7rczvPPP49Zs2ZVmr58+XKYTCZPm3tZnnuuP/buDcXf//4Tbrwxs062SURERNRQFRcXY+zYscjLy0NgYKDb+VT1fNZEXFycU1Dt378/rrnmGrz99tt44YUXXC4zbdo0pKSk2K/n5+cjOjoaQ4cOrfLO1JTFYkFaWhqGDBkC/Z8Heb76qg4AcN11PTFiRA+vb7Mhc1Uvco21Uof1Uof18hxrpQ7rpQ7rJSl7qqujKnyGhIRAp9MhOzvbaXp2djYiIiI8Woder0evXr1w5MgRt/MYDAYYDAaXy9bmg1p+/WVlcpqfnw9POnKjth+PqwlrpQ7rpQ7r5TnWSh3WS53GXi9P77uqE458fX3Ru3dvpKen26fZbDakp6c79W5WxWq14tdff0WLFi3UbLrO8Wx3IiIiIu9Tvds9JSUFiYmJ6NOnD/r27Yt58+ahqKgISUlJAIAJEyYgKioKqampAIDZs2fj+uuvR/v27XHx4kX8+9//xvHjx/HXv/7Vu/fEyxg+iYiIiLxPdfhMSEhAbm4uZsyYgaysLPTs2RPr1q2zD5904sQJaLWODtULFy5g0qRJyMrKQnBwMHr37o2tW7ciNjbWe/eiFjB8EhEREXlfjU44Sk5ORnJyssvbNm7c6HT99ddfx+uvv16TzdQrjvNJRERE5H38bXc3zGb5lz2fRERERN7D8OkGd7sTEREReR/DpxsMn0RERETex/DpBsMnERERkfcxfLrB8ElERETkfQyfbjB8EhEREXkfw6cLQgBWq/yf4ZOIiIjIexg+XVB6PQGO80lERETkTQyfLihjfALs+SQiIiLyJoZPF8r3fDJ8EhEREXkPw6cLDJ9EREREtYPh0wUlfOp0gEZTv20hIiIiupowfLrAYZaIiIiIagfDpwsMn0RERES1g+HTBYZPIiIiotrB8OmCMtQSx/gkIiIi8i6GTxfY80lERERUOxg+XWD4JCIiIqodDJ8uMHwSERER1Q6GTxcYPomIiIhqB8OnCwyfRERERLWD4dMFhk8iIiKi2sHw6YISPjnUEhEREZF3+dR3A65Eyjif7PkkIiLyPqvVCovS03MVsFgs8PHxQUlJCaxWa303p9bo9XrodLrLXg/Dpwvc7U5EROR9QghkZWXh4sWL9d0UrxJCICIiAidPnoRGo6nv5tSqoKAgREREXNb9ZPh0geGTiIjI+5TgGRYWBpPJdNUENZvNhsLCQvj7+0OrvTqPaBRCoLi4GDk5OQCAFi1a1HhdDJ8uMHwSERF5l9VqtQfP5s2b13dzvMpms8FsNsNoNF614RMA/Pz8AAA5OTkICwur8S74q7dCl4Hhk4iIyLuUYzxNJlM9t4Quh/L4Xc4xuwyfLjB8EhER1Y6rZVd7Y+WNx4/h0wWGTyIiIqLawfDpgjLUEsf5JCIiIm+KiYnBvHnz6rsZ9apG4XPhwoWIiYmB0WhEv379sGPHDo+WW7FiBTQaDe68886abLbOsOeTiIiIFDfffDOeeOIJr6xr586deOihh7yyroZKdfhcuXIlUlJSMHPmTOzatQs9evTAsGHD7Kfeu3Ps2DE89dRTuPHGG2vc2LrC8ElERESeEkKgrKzMo3lDQ0Mb/UlXqsPn3LlzMWnSJCQlJSE2NhaLFy+GyWTCkiVL3C5jtVoxbtw4zJo1C23btr2sBtcFhk8iIiICgIkTJ2LTpk2YP38+NBoNNBoN3nvvPWg0Gnz99dfo3bs3/Pz88OOPP+L333/HqFGjEB4eDn9/f1x33XX49ttvndZXcbe7RqPB//3f/2H06NEwmUzo0KEDvvzyS4/aZrVa8eCDD6JNmzbw8/NDp06dMH/+/ErzLVmyBF26dIHBYECLFi2QnJxsv+3ixYt4+OGHER4eDqPRiK5du2L16tU1K5aHVI3zaTabkZGRgWnTptmnabVaDB48GNu2bXO73OzZsxEWFoYHH3wQ33//fbXbKS0tRWlpqf16fn4+AHlaf238HJeyTuVvaakWgA5arRUWi83r22voKtaL3GOt1GG91GG9PMdaqVMb9bJYLBBCwGazwWaTn61CAMXFXtuEKiYT4MmJ26+//jp+++03dOnSBbNmzQIA7Nu3DwDwzDPP4NVXX0WbNm2g1+tx4cIF3HbbbXjhhRdgMBjw/vvvIz4+HgcOHECrVq3s61TqoJg1axZefvllvPLKK3jzzTcxbtw4HD16FM2aNauybWVlZYiKisLKlSvRvHlzbN26FZMnT0Z4eDjuvfdeAMBbb72Fp556CqmpqbjtttuQl5eHrVu32h+H4cOHo6CgAP/73//Qrl077N+/HxqNxql95dlsNgghYLFYKo3z6enzRVX4PHv2LKxWK8LDw52mh4eH4+DBgy6X2bJlC959913s2bPH4+2kpqbaH+Dy1q9fX6td1WlpaQCAI0e6A2iD48cPY+3aQ7W2vYZOqRdVj7VSh/VSh/XyHGuljjfr5ePjg4iICBQWFsL855m9RUVAy5ZBXtuGGqdOXUSTJtXPp9FooNVq4ePjY88gSgfZ008/jX79+tnnDQ4OdtrD+9RTT+HTTz/FRx99ZD/O02azoaSkxN6xBgB/+ctfMHLkSPs6FyxYgI0bN2Lw4MHVti8lJcX+f3x8PDZv3owPP/wQt912GwDgxRdfxJQpUzBx4kQAQEREBDp16oT8/Hxs2LABO3bswPbt29G+fXsAwMCBAwHAqX3lmc1mXLp0CZs3b650qEGxh98kavUXjgoKCjB+/Hi88847CAkJ8Xi5adOmORUzPz8f0dHRGDp0KAIDA73eTovFgrS0NAwZMgR6vR5ffimT/DXXdMCIEe28vr2GrmK9yD3WSh3WSx3Wy3OslTq1Ua+SkhKcPHkS/v7+MBqNAIAa/kCOVwQGBnoUPgEZnH19fe0ZRAmhN954IwIDAyGEQEFBATQaDWbPno21a9fizJkzKCsrw6VLl5Cbm2tfVqvVwmg0OuWZPn362K8HBgYiMDAQhYWFHmWeRYsWYenSpThx4gQuXboEs9mMnj17IjAwEDk5OThz5gyGDx/ucl2HDx9Gy5Ytce2113pWCMjH0c/PDwMHDrQ/jgp3gbUiVeEzJCQEOp0O2dnZTtOzs7MRERFRaf7ff/8dx44dQ3x8vH2a0o3r4+ODQ4cOoV27yuHOYDDAYDBUmq7X62v1TUNZv9UqrxuNOuj19fjKuMLV9uNxNWGt1GG91GG9PMdaqePNelmtVnsvovITlP7+QGGhV1avmsmk9Wi3u0JpOwD734CAAGi1Wnu2mTp1Kr799lu89tpraN++Pfz8/HD33XfDYrE4/exm+XUBMvdUvL38dtxZsWIF/vGPf2DOnDmIi4tDQEAA/v3vf2P79u3QarVo8me6Ll9z5xqYPNpOeVqtFhqNxuVzw9Pniqrw6evri969eyM9Pd0+XJLNZkN6errTwauKzp0749dff3Wa9txzz6GgoADz589HdHS0ms3XGY7zSUREVPs0Gnjc+1iffH19YVV6pqqwdetWTJw4EaNHjwYAFBYW4tixY7XWrh9++AH9+/fHo48+ap/2+++/2/8PCAhATEwM0tPTMWjQoErLd+/eHadOncJvv/2Gjh071lo7K1K92z0lJQWJiYno06cP+vbti3nz5qGoqAhJSUkAgAkTJiAqKgqpqan2s6bKCwoKAoBK068kPNudiIiIFDExMdi+fTuOHTsGf39/tyfjtG/fHqtWrUJ8fDw0Gg2mT5/udl5v6NChA/73v//hm2++QZs2bfD+++9j586daNOmjX2e559/HpMnT0ZYWJj95KIffvgBf/vb33DTTTdh4MCBuOuuuzB37ly0b98eBw8ehEajsR8zWhtUD7WUkJCA1157DTNmzEDPnj2xZ88erFu3zn4S0okTJ3DmzBmvN7QuMXwSERGR4qmnnoJOp0NsbCxCQ0Nx4sQJl/PNmTMHwcHB6N+/P+Lj4zFs2DBVx1Oq9fDDD2PMmDFISEhAv379cO7cOadeUABITEzEvHnzsGjRInTp0gW33347Dh8+bL/9008/xXXXXYf77rsPsbGxmDp1qke9vJejRiccJScnu9zNDgAbN26sctn33nuvJpusUwyfREREpOjYsWOlISWVs8fLi4mJwYYNG5ymTZkyxel6xd3wQohK67l48aJH7TIYDFi6dCmWLl3qND01NdXp+sMPP4yHH37Y5TqaNWtW5VjttYG/7e4CwycRERFR7WD4dIHhk4iIiOrb5MmT4e/v7/IyefLk+m5ejdXqOJ8NFcMnERER1bfZs2fjqaeecnlbbYx7XlcYPl1g+CQiIqL6FhYWhrCwsPpuhtdxt7sLHOeTiIiIqHYwfLrAnk8iIiKi2sHw6QLDJxEREVHtYPh0geGTiIiIqHYwfLrA8ElERERUOxg+XWD4JCIiIqodDJ8uMHwSERGRt8TExGDevHn13YwrBsOnC8pQSwyfRERERN7F8OmC0vPJcT6JiIiIvIvh0wXudiciIqoDQgBFRfVzEcKjJv7nP/9BZGQkbDab0/RRo0bhgQcewO+//44777wTHTt2RGBgIK677jp8++23NS7J3Llz0a1bNzRp0gTR0dF49NFHUVhY6DTPDz/8gJtvvhkmkwnBwcEYNmwYLly4AACw2Wx49dVX0b59exgMBrRq1QovvvhijdtTGxg+K7DZ5AVg+CQiIqpVxcWAv3/9XIqLPWriPffcg3PnzuG7776zTzt//jzWrVuHcePGobCwEMOHD8fnn3+OjIwM3HbbbYiPj8eJEydqVBKtVos33ngD+/btw3//+19s2LABU6dOtd++Z88e3HrrrYiNjcW2bduwZcsWxMfHw2q1AgCmTZuGl19+GdOnT8f+/fuxfPlyhIeH16gttYW/7V6B0usJMHwSERE1dsHBwRg+fDiWL1+OW2+9FQDwySefICQkBIMGDYJWq0W3bt2Qn5+PwMBAvPDCC/jss8/w5ZdfIjk5WfX2nnjiCfv/MTEx+Ne//oXJkydj0aJFAIBXX30Vffr0sV8HgC5dugAACgoKMH/+fLz55ptITEwEALRr1w433HBDTe9+rWD4rIDhk4iIqI6YTECFXcp1um0PjRs3DpMmTcKiRYtgMBiwbNky/OUvf4FWq0VhYSFmzpyJ1atXIzs7G2VlZbh06VKNez6//fZbpKam4uDBg8jPz0dZWRlKSkpQXFwMk8mEPXv24J577nG57IEDB1BaWmoPyVcqhs8KGD6JiIjqiEYDNGlS362oVnx8PIQQWLNmDa677jp8//33eP311wEATz31FNLS0jBr1iz7sZp33303zMrQOSocO3YMt99+Ox555BG8+OKLaNasGbZs2YIHH3wQZrMZJpMJfn5+bpev6rYrCY/5rIDhk4iIiMozGo0YM2YMli1bhg8//BCdOnXCtddeC0Ce/JOYmIjbb78d3bp1Q0REBI4dO1aj7WRkZMBms2HOnDm4/vrr0bFjR5w+fdppnu7duyM9Pd3l8h06dICfn5/b268U7PmsQPmi4uMjv5ARERERjRs3Drfffjv27duH+++/3z69Q4cO+OyzzzBo0CD4+/tj5syZlc6M91T79u1hsViwYMECxMfH44cffsDixYud5pk2bRq6deuGRx99FJMnT4avry++++473HPPPQgJCcHTTz+NqVOnwtfXFwMGDEBubi727duHBx988LLuvzex57MCDrNEREREFd1yyy1o1qwZDh06hLFjx9qnz5071z7c0ahRozBs2DB7r6haPXr0wNy5c/HKK6+ga9euWLZsGVJTU53m6dixI9avX4+ff/4Zffv2RVxcHL744gv4+Mj+xOnTp+Pvf/87ZsyYgWuuuQYJCQnIycmp+R2vBez5rIDhk4iIiCrSarWVdoED8oz0b7/91n62u1arxZQpU5zmUbMb/sknn8STTz7pNG38+PFO12+66Sb88MMPbtv57LPP4tlnn/V4m3WN4bOCFi2Azz+v71YQERERXZ24272CgABg1Ch5ISIiIvKWZcuWwd/f3+VFGauzMWDPJxEREVEduOOOO9CvXz+Xt+kb0fF+DJ9EREREdSAgIAABAQH13Yx6x93uREREVGdqOgwRXRm88fix55OIiIhqna+vr/2M8dDQUPj6+kJzlQyobbPZYDabUVJSAq326uzXE0LAbDYjNzcXWq0Wvr6+NV4XwycRERHVOq1WizZt2uDMmTMuhyxqyIQQuHTpEvz8/K6aQO2OyWRCq1atLitkM3wSERFRnfD19UWrVq1QVlYGq9Va383xGovFgs2bN2PgwIFX9YlDOp0OPj4+lx2wGT6JiIiozmg0Guj1+qsqpOl0OpSVlcFoNF5V96u21KjPdOHChYiJiYHRaES/fv2wY8cOt/OuWrUKffr0QVBQEJo0aYKePXvi/fffr3GDiYiIiKjhUh0+V65ciZSUFMycORO7du1Cjx49MGzYMLe/G9qsWTM8++yz2LZtG3755RckJSUhKSkJ33zzzWU3noiIiIgaFtXhc+7cuZg0aRKSkpIQGxuLxYsXw2QyYcmSJS7nv/nmmzF69Ghcc801aNeuHR5//HF0794dW7ZsuezGExEREVHDouqYT7PZjIyMDEybNs0+TavVYvDgwdi2bVu1ywshsGHDBhw6dAivvPKK2/lKS0tRWlpqv56XlwcAOH/+PCwWi5ome8RisaC4uBjnzp3jsRoeYL08x1qpw3qpw3p5jrVSh/VSh/WSCgoKAMi8VxVV4fPs2bOwWq0IDw93mh4eHo6DBw+6XS4vLw9RUVEoLS2FTqfDokWLMGTIELfzp6amYtasWZWmt2nTRk1ziYiIiKiOFRQUoGnTpm5vr5Oz3QMCArBnzx4UFhYiPT0dKSkpaNu2LW6++WaX80+bNg0pKSn26zabDefPn0fz5s1rZfys/Px8REdH4+TJkwgMDPT6+q82rJfnWCt1WC91WC/PsVbqsF7qsF6SEAIFBQWIjIyscj5V4TMkJAQ6nQ7Z2dlO07OzsxEREeF2Oa1Wi/bt2wMAevbsiQMHDiA1NdVt+DQYDDAYDE7TgoKC1DS1RgIDAxv1k0Yt1stzrJU6rJc6rJfnWCt1WC91WC9U2eOpUHXCka+vL3r37o309HT7NJvNhvT0dMTFxXm8HpvN5nRMJxERERE1Dqp3u6ekpCAxMRF9+vRB3759MW/ePBQVFSEpKQkAMGHCBERFRSE1NRWAPH6zT58+aNeuHUpLS7F27Vq8//77eOutt7x7T4iIiIjoiqc6fCYkJCA3NxczZsxAVlYWevbsiXXr1tlPQjpx4oTT730WFRXh0UcfxalTp+Dn54fOnTvjgw8+QEJCgvfuxWUyGAyYOXNmpV395Brr5TnWSh3WSx3Wy3OslTqslzqslzoaUd358EREREREXlKjn9ckIiIiIqoJhk8iIiIiqjMMn0RERERUZxg+iYiIiKjOMHwSERERUZ1h+ASwcOFCxMTEwGg0ol+/ftixY0d9N6nepaam4rrrrkNAQADCwsJw55134tChQ07zlJSUYMqUKWjevDn8/f1x1113Vfr1q8bo5ZdfhkajwRNPPGGfxlo5y8zMxP3334/mzZvDz88P3bp1w08//WS/XQiBGTNmoEWLFvDz88PgwYNx+PDhemxx/bFarZg+fTratGkDPz8/tGvXDi+88ALKD1TSmOu1efNmxMfHIzIyEhqNBp9//rnT7Z7U5vz58xg3bhwCAwMRFBSEBx98EIWFhXV4L+pGVbWyWCx4+umn0a1bNzRp0gSRkZGYMGECTp8+7bSOxlIroPrnVnmTJ0+GRqPBvHnznKY3pnqp0ejD58qVK5GSkoKZM2di165d6NGjB4YNG4acnJz6blq92rRpE6ZMmYIff/wRaWlpsFgsGDp0KIqKiuzzPPnkk/jqq6/w8ccfY9OmTTh9+jTGjBlTj62ufzt37sTbb7+N7t27O01nrRwuXLiAAQMGQK/X4+uvv8b+/fsxZ84cBAcH2+d59dVX8cYbb2Dx4sXYvn07mjRpgmHDhqGkpKQeW14/XnnlFbz11lt48803ceDAAbzyyit49dVXsWDBAvs8jbleRUVF6NGjBxYuXOjydk9qM27cOOzbtw9paWlYvXo1Nm/ejIceeqiu7kKdqapWxcXF2LVrF6ZPn45du3Zh1apVOHToEO644w6n+RpLrYDqn1uKzz77DD/++KPL3zNvTPVSRTRyffv2FVOmTLFft1qtIjIyUqSmptZjq648OTk5AoDYtGmTEEKIixcvCr1eLz7++GP7PAcOHBAAxLZt2+qrmfWqoKBAdOjQQaSlpYmbbrpJPP7440II1qqip59+Wtxwww1ub7fZbCIiIkL8+9//tk+7ePGiMBgM4sMPP6yLJl5RRo4cKR544AGnaWPGjBHjxo0TQrBe5QEQn332mf26J7XZv3+/ACB27txpn+frr78WGo1GZGZm1lnb61rFWrmyY8cOAUAcP35cCNF4ayWE+3qdOnVKREVFib1794rWrVuL119/3X5bY65XdRp1z6fZbEZGRgYGDx5sn6bVajF48GBs27atHlt25cnLywMANGvWDACQkZEBi8XiVLvOnTujVatWjbZ2U6ZMwciRI51qArBWFX355Zfo06cP7rnnHoSFhaFXr15455137LcfPXoUWVlZTvVq2rQp+vXr1yjr1b9/f6Snp+O3334DAPz888/YsmULhg8fDoD1qoontdm2bRuCgoLQp08f+zyDBw+GVqvF9u3b67zNV5K8vDxoNBoEBQUBYK0qstlsGD9+PP7xj3+gS5culW5nvdxT/fOaV5OzZ8/CarXafxpUER4ejoMHD9ZTq648NpsNTzzxBAYMGICuXbsCALKysuDr62t/U1KEh4cjKyurHlpZv1asWIFdu3Zh586dlW5jrZz98ccfeOutt5CSkoJ//vOf2LlzJx577DH4+voiMTHRXhNXr8vGWK9nnnkG+fn56Ny5M3Q6HaxWK1588UWMGzcOAFivKnhSm6ysLISFhTnd7uPjg2bNmjXq+pWUlODpp5/Gfffdh8DAQACsVUWvvPIKfHx88Nhjj7m8nfVyr1GHT/LMlClTsHfvXmzZsqW+m3JFOnnyJB5//HGkpaXBaDTWd3OueDabDX369MFLL70EAOjVqxf27t2LxYsXIzExsZ5bd+X56KOPsGzZMixfvhxdunTBnj178MQTTyAyMpL1olphsVhw7733QgiBt956q76bc0XKyMjA/PnzsWvXLmg0mvpuToPTqHe7h4SEQKfTVTrrODs7GxEREfXUqitLcnIyVq9eje+++w4tW7a0T4+IiIDZbMbFixed5m+MtcvIyEBOTg6uvfZa+Pj4wMfHB5s2bcIbb7wBHx8fhIeHs1bltGjRArGxsU7TrrnmGpw4cQIA7DXh61L6xz/+gWeeeQZ/+ctf0K1bN4wfPx5PPvkkUlNTAbBeVfGkNhEREZVOMC0rK8P58+cbZf2U4Hn8+HGkpaXZez0B1qq877//Hjk5OWjVqpX9ff/48eP4+9//jpiYGACsV1Uadfj09fVF7969kZ6ebp9ms9mQnp6OuLi4emxZ/RNCIDk5GZ999hk2bNiANm3aON3eu3dv6PV6p9odOnQIJ06caHS1u/XWW/Hrr79iz5499kufPn0wbtw4+/+slcOAAQMqDdv122+/oXXr1gCANm3aICIiwqle+fn52L59e6OsV3FxMbRa57dqnU4Hm80GgPWqiie1iYuLw8WLF5GRkWGfZ8OGDbDZbOjXr1+dt7k+KcHz8OHD+Pbbb9G8eXOn21krh/Hjx+OXX35xet+PjIzEP/7xD3zzzTcAWK8q1fcZT/VtxYoVwmAwiPfee0/s379fPPTQQyIoKEhkZWXVd9Pq1SOPPCKaNm0qNm7cKM6cOWO/FBcX2+eZPHmyaNWqldiwYYP46aefRFxcnIiLi6vHVl85yp/tLgRrVd6OHTuEj4+PePHFF8Xhw4fFsmXLhMlkEh988IF9npdfflkEBQWJL774Qvzyyy9i1KhRok2bNuLSpUv12PL6kZiYKKKiosTq1avF0aNHxapVq0RISIiYOnWqfZ7GXK+CggKxe/dusXv3bgFAzJ07V+zevdt+hrYntbnttttEr169xPbt28WWLVtEhw4dxH333Vdfd6nWVFUrs9ks7rjjDtGyZUuxZ88ep/f90tJS+zoaS62EqP65VVHFs92FaFz1UqPRh08hhFiwYIFo1aqV8PX1FX379hU//vhjfTep3gFweVm6dKl9nkuXLolHH31UBAcHC5PJJEaPHi3OnDlTf42+glQMn6yVs6+++kp07dpVGAwG0blzZ/Gf//zH6XabzSamT58uwsPDhcFgELfeeqs4dOhQPbW2fuXn54vHH39ctGrVShiNRtG2bVvx7LPPOgWCxlyv7777zuV7VWJiohDCs9qcO3dO3HfffcLf318EBgaKpKQkUVBQUA/3pnZVVaujR4+6fd//7rvv7OtoLLUSovrnVkWuwmdjqpcaGiHK/UwGEREREVEtatTHfBIRERFR3WL4JCIiIqI6w/BJRERERHWG4ZOIiIiI6gzDJxERERHVGYZPIiIiIqozDJ9EREREVGcYPomIiIiozjB8EhEREVGdYfgkIiIiojrD8ElEREREdeb/Adctwqs5xE/TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg16_acc = vgg16_history.history['accuracy']\n",
    "vgg16_val_acc = vgg16_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(vgg16_acc)+1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('vgg16_ Accuracy')\n",
    "plt.plot(epochs, vgg16_acc, 'b', label='train_acc')\n",
    "plt.plot(epochs, vgg16_val_acc, 'r', label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbee8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 307s 3s/step - loss: 0.0837 - accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08370903879404068, 0.9827777743339539]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_vgg16= load_model(vgg16_path)\n",
    "vgg16_test_res = best_vgg16.evaluate(x_ts, y_test)\n",
    "vgg16_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1adfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 293s 3s/step\n",
      "time : 293.96240043640137\n",
      "pred shape: (3600, 30)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pred = best_vgg16.predict(x_ts)\n",
    "vgg16_pred_time = time.time()-start_time\n",
    "print(\"time : {}\".format(vgg16_pred_time))\n",
    "print(\"pred shape:\", pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec49d9",
   "metadata": {},
   "source": [
    "### # xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "162e1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 200, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 99, 74, 32)   864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 99, 74, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 99, 74, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 97, 72, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 97, 72, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 97, 72, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 97, 72, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 97, 72, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 97, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 97, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 97, 72, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 49, 36, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 49, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 49, 36, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 49, 36, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 49, 36, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 49, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 49, 36, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 49, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 49, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 49, 36, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 25, 18, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 25, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 18, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 18, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 25, 18, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 25, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 25, 18, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 25, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 25, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 25, 18, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 13, 9, 728)   186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 13, 9, 728)   0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13, 9, 728)   2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 9, 728)   0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 13, 9, 728)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 13, 9, 728)   536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 13, 9, 728)   2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 13, 9, 728)   0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 13, 9, 728)   536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 13, 9, 728)   2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 13, 9, 728)   0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 13, 9, 728)   536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 13, 9, 728)   2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 9, 728)   0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 13, 9, 728)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 13, 9, 728)   536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 13, 9, 728)   2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 13, 9, 728)   0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 13, 9, 728)   536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 13, 9, 728)   2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 13, 9, 728)   0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 13, 9, 728)   536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 13, 9, 728)   2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 9, 728)   0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 13, 9, 728)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 13, 9, 728)   536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 13, 9, 728)   2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 13, 9, 728)   0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 13, 9, 728)   536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 13, 9, 728)   2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 13, 9, 728)   0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 13, 9, 728)   536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 13, 9, 728)   2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 9, 728)   0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 13, 9, 728)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 13, 9, 728)   536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 13, 9, 728)   2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 13, 9, 728)   0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 13, 9, 728)   536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 13, 9, 728)   2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 13, 9, 728)   0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 13, 9, 728)   536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 13, 9, 728)   2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 13, 9, 728)   0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 13, 9, 728)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 13, 9, 728)   536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 13, 9, 728)   2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 13, 9, 728)   0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 13, 9, 728)   536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 13, 9, 728)   2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 13, 9, 728)   0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 13, 9, 728)   536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 13, 9, 728)   2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 13, 9, 728)   0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 13, 9, 728)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 13, 9, 728)   536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 13, 9, 728)   2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 13, 9, 728)   0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 13, 9, 728)   536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 13, 9, 728)   2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 13, 9, 728)   0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 13, 9, 728)   536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 13, 9, 728)   2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 13, 9, 728)   0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 13, 9, 728)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 13, 9, 728)   536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 13, 9, 728)   2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 13, 9, 728)   0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 13, 9, 728)   536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 13, 9, 728)   2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 13, 9, 728)   0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 13, 9, 728)   536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 13, 9, 728)   2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 13, 9, 728)   0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 13, 9, 728)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 13, 9, 728)   536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 13, 9, 728)   2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 13, 9, 728)   0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 13, 9, 728)   536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 13, 9, 728)   2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 13, 9, 728)   0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 13, 9, 728)   536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 13, 9, 728)   2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 9, 728)   0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 13, 9, 728)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 13, 9, 728)   536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 13, 9, 728)   2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 13, 9, 728)   0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 13, 9, 1024)  752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 13, 9, 1024)  4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 5, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 5, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 5, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 5, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 1, 2048)   0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          1048832     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           3870        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,947,078\n",
      "Trainable params: 21,892,550\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a021ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "360/360 [==============================] - 217s 585ms/step - loss: 2.6228 - accuracy: 0.2855 - val_loss: 0.6259 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85312, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 2/150\n",
      "360/360 [==============================] - 195s 539ms/step - loss: 0.5811 - accuracy: 0.8462 - val_loss: 0.1369 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85312 to 0.96667, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 3/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.2000 - accuracy: 0.9480 - val_loss: 0.0809 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.96667 to 0.97847, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 4/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.1138 - accuracy: 0.9718 - val_loss: 0.0626 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.97847 to 0.98368, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 5/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 0.0685 - accuracy: 0.9838 - val_loss: 0.0536 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98368 to 0.98611, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 6/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0453 - accuracy: 0.9900 - val_loss: 0.0478 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.98611 to 0.98819, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 7/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0356 - accuracy: 0.9931 - val_loss: 0.0474 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98819 to 0.98854, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 8/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0248 - accuracy: 0.9951 - val_loss: 0.0458 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.98854\n",
      "Epoch 9/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0420 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.98854 to 0.99063, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 10/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.0410 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99063\n",
      "Epoch 11/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0402 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.99063 to 0.99132, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 12/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0147 - accuracy: 0.9972 - val_loss: 0.0409 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99132\n",
      "Epoch 13/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0436 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99132\n",
      "Epoch 14/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.0430 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99132\n",
      "Epoch 15/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.0436 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99132\n",
      "Epoch 16/150\n",
      "360/360 [==============================] - 194s 540ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0434 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99132\n",
      "Epoch 17/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0418 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99132\n",
      "Epoch 18/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0427 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99132\n",
      "Epoch 19/150\n",
      "360/360 [==============================] - 194s 540ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0453 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99132\n",
      "Epoch 20/150\n",
      "360/360 [==============================] - 195s 541ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0441 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99132\n",
      "Epoch 21/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0448 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.99132\n",
      "Epoch 22/150\n",
      "360/360 [==============================] - 194s 540ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.99132\n",
      "Epoch 23/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0427 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.99132\n",
      "Epoch 24/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0455 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.99132\n",
      "Epoch 25/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0473 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.99132\n",
      "Epoch 26/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0460 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.99132\n",
      "Epoch 27/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0420 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.99132\n",
      "Epoch 28/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.99132\n",
      "Epoch 29/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0452 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.99132\n",
      "Epoch 30/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0418 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.99132\n",
      "Epoch 31/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0444 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.99132\n",
      "Epoch 32/150\n",
      "360/360 [==============================] - 195s 541ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0457 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.99132\n",
      "Epoch 33/150\n",
      "360/360 [==============================] - 194s 540ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0457 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.99132\n",
      "Epoch 34/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0462 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.99132\n",
      "Epoch 35/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0484 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.99132\n",
      "Epoch 36/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0498 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.99132\n",
      "Epoch 37/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0484 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.99132\n",
      "Epoch 38/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0478 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.99132\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0485 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.99132\n",
      "Epoch 40/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0495 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.99132\n",
      "Epoch 41/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0479 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.99132\n",
      "Epoch 42/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0466 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.99132\n",
      "Epoch 43/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0471 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.99132\n",
      "Epoch 44/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0483 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.99132\n",
      "Epoch 45/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0465 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.99132\n",
      "Epoch 46/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0466 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.99132\n",
      "Epoch 47/150\n",
      "360/360 [==============================] - 193s 538ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0484 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.99132\n",
      "Epoch 48/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0466 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.99132\n",
      "Epoch 49/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0488 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.99132\n",
      "Epoch 50/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0488 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.99132\n",
      "Epoch 51/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0481 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.99132\n",
      "Epoch 52/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0475 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.99132\n",
      "Epoch 53/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0468 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.99132\n",
      "Epoch 54/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.99132\n",
      "Epoch 55/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0487 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.99132 to 0.99167, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 56/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0486 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.99167\n",
      "Epoch 57/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.99167\n",
      "Epoch 58/150\n",
      "360/360 [==============================] - 193s 538ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.99167\n",
      "Epoch 59/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0482 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.99167\n",
      "Epoch 60/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0472 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.99167\n",
      "Epoch 61/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.99167\n",
      "Epoch 62/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0484 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.99167\n",
      "Epoch 63/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0485 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.99167\n",
      "Epoch 64/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0488 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.99167\n",
      "Epoch 65/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0497 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.99167\n",
      "Epoch 66/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 9.7060e-04 - accuracy: 0.9999 - val_loss: 0.0474 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.99167\n",
      "Epoch 67/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0478 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.99167 to 0.99201, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 68/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.99201\n",
      "Epoch 69/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0477 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.99201\n",
      "Epoch 70/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 9.9641e-04 - accuracy: 0.9999 - val_loss: 0.0476 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.99201\n",
      "Epoch 71/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.99201\n",
      "Epoch 72/150\n",
      "360/360 [==============================] - 193s 538ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0507 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.99201\n",
      "Epoch 73/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 9.4866e-04 - accuracy: 0.9998 - val_loss: 0.0506 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.99201\n",
      "Epoch 74/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.99201\n",
      "Epoch 75/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0523 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.99201\n",
      "Epoch 76/150\n",
      "360/360 [==============================] - 193s 538ms/step - loss: 8.6718e-04 - accuracy: 0.9999 - val_loss: 0.0519 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.99201\n",
      "Epoch 77/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0505 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.99201\n",
      "Epoch 78/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.99201\n",
      "Epoch 79/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.99201\n",
      "Epoch 80/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0526 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.99201\n",
      "Epoch 81/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0520 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.99201\n",
      "Epoch 82/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.0623e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.99201\n",
      "Epoch 83/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 9.4013e-04 - accuracy: 0.9999 - val_loss: 0.0518 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.99201\n",
      "Epoch 84/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 6.9954e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.99201\n",
      "Epoch 85/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0502 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.99201\n",
      "Epoch 86/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.5185e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.99201\n",
      "Epoch 87/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0528 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.99201\n",
      "Epoch 88/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 9.0784e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.99201\n",
      "Epoch 89/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.3491e-04 - accuracy: 0.9999 - val_loss: 0.0538 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.99201\n",
      "Epoch 90/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 9.9203e-04 - accuracy: 0.9998 - val_loss: 0.0508 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.99201\n",
      "Epoch 91/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0484 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.99201 to 0.99236, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 92/150\n",
      "360/360 [==============================] - 192s 533ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0488 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.99236 to 0.99271, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 93/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0484 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.99271\n",
      "Epoch 94/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 6.4086e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.99271\n",
      "Epoch 95/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 9.6713e-04 - accuracy: 0.9998 - val_loss: 0.0488 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.99271\n",
      "Epoch 96/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 9.5131e-04 - accuracy: 0.9998 - val_loss: 0.0490 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.99271\n",
      "Epoch 97/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0492 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.99271\n",
      "Epoch 98/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 6.7130e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.99271\n",
      "Epoch 99/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0508 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.99271\n",
      "Epoch 100/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 6.8779e-04 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.99271\n",
      "Epoch 101/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0492 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.99271\n",
      "Epoch 102/150\n",
      "360/360 [==============================] - 194s 539ms/step - loss: 6.6864e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.99271\n",
      "Epoch 103/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 4.9375e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.99271\n",
      "Epoch 104/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0497 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.99271\n",
      "Epoch 105/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0485 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.99271\n",
      "Epoch 106/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 9.2081e-04 - accuracy: 0.9997 - val_loss: 0.0485 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.99271\n",
      "Epoch 107/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 9.8208e-04 - accuracy: 0.9998 - val_loss: 0.0493 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.99271\n",
      "Epoch 108/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 7.2337e-04 - accuracy: 0.9999 - val_loss: 0.0493 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.99271\n",
      "Epoch 109/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 7.3556e-04 - accuracy: 0.9999 - val_loss: 0.0517 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.99271\n",
      "Epoch 110/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0512 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.99271\n",
      "Epoch 111/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 6.3395e-04 - accuracy: 0.9999 - val_loss: 0.0508 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.99271\n",
      "Epoch 112/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.7087e-04 - accuracy: 0.9998 - val_loss: 0.0510 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.99271\n",
      "Epoch 113/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0492 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.99271\n",
      "Epoch 114/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 9.0480e-04 - accuracy: 0.9997 - val_loss: 0.0508 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.99271\n",
      "Epoch 115/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 6.9504e-04 - accuracy: 0.9998 - val_loss: 0.0511 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.99271\n",
      "Epoch 116/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 6.7253e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.99271\n",
      "Epoch 117/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 9.6208e-04 - accuracy: 0.9997 - val_loss: 0.0537 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.99271\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 193s 535ms/step - loss: 5.5038e-04 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.99271\n",
      "Epoch 119/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 9.0444e-04 - accuracy: 0.9998 - val_loss: 0.0500 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.99271\n",
      "Epoch 120/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 7.0805e-04 - accuracy: 0.9999 - val_loss: 0.0501 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.99271 to 0.99306, saving model to D:/dasol\\xception_best_model.h5\n",
      "Epoch 121/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 8.1239e-04 - accuracy: 0.9999 - val_loss: 0.0509 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.99306\n",
      "Epoch 122/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 5.3860e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.99306\n",
      "Epoch 123/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.3694e-04 - accuracy: 0.9998 - val_loss: 0.0504 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.99306\n",
      "Epoch 124/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.4167e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.99306\n",
      "Epoch 125/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 7.4241e-04 - accuracy: 0.9999 - val_loss: 0.0505 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.99306\n",
      "Epoch 126/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 6.6509e-04 - accuracy: 0.9999 - val_loss: 0.0504 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.99306\n",
      "Epoch 127/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 4.4794e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.99306\n",
      "Epoch 128/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.2271e-04 - accuracy: 0.9999 - val_loss: 0.0506 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.99306\n",
      "Epoch 129/150\n",
      "360/360 [==============================] - 192s 533ms/step - loss: 5.0045e-04 - accuracy: 0.9999 - val_loss: 0.0507 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.99306\n",
      "Epoch 130/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.0622e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.99306\n",
      "Epoch 131/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 6.6551e-04 - accuracy: 0.9999 - val_loss: 0.0521 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.99306\n",
      "Epoch 132/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 5.4096e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.99306\n",
      "Epoch 133/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 7.7471e-04 - accuracy: 0.9999 - val_loss: 0.0516 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.99306\n",
      "Epoch 134/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 6.0754e-04 - accuracy: 0.9999 - val_loss: 0.0516 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.99306\n",
      "Epoch 135/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 5.9972e-04 - accuracy: 0.9998 - val_loss: 0.0511 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.99306\n",
      "Epoch 136/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.0074e-04 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.99306\n",
      "Epoch 137/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 3.7298e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.99306\n",
      "Epoch 138/150\n",
      "360/360 [==============================] - 194s 538ms/step - loss: 6.8172e-04 - accuracy: 0.9999 - val_loss: 0.0518 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.99306\n",
      "Epoch 139/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 4.4720e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.99306\n",
      "Epoch 140/150\n",
      "360/360 [==============================] - 192s 535ms/step - loss: 7.1141e-04 - accuracy: 0.9999 - val_loss: 0.0522 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.99306\n",
      "Epoch 141/150\n",
      "360/360 [==============================] - 193s 536ms/step - loss: 8.3520e-04 - accuracy: 0.9999 - val_loss: 0.0525 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.99306\n",
      "Epoch 142/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.4863e-04 - accuracy: 0.9999 - val_loss: 0.0526 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.99306\n",
      "Epoch 143/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0512 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.99306\n",
      "Epoch 144/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 7.4350e-04 - accuracy: 0.9999 - val_loss: 0.0507 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.99306\n",
      "Epoch 145/150\n",
      "360/360 [==============================] - 193s 537ms/step - loss: 6.1429e-04 - accuracy: 0.9998 - val_loss: 0.0495 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.99306\n",
      "Epoch 146/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 5.3780e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.99306\n",
      "Epoch 147/150\n",
      "360/360 [==============================] - 192s 534ms/step - loss: 4.7194e-04 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.99306\n",
      "Epoch 148/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.0366e-04 - accuracy: 0.9999 - val_loss: 0.0486 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.99306\n",
      "Epoch 149/150\n",
      "360/360 [==============================] - 193s 535ms/step - loss: 5.3868e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.99306\n",
      "Epoch 150/150\n",
      "360/360 [==============================] - 192s 533ms/step - loss: 4.9950e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.99306\n"
     ]
    }
   ],
   "source": [
    "xception_history = xception.fit(x_trn, y_train, \n",
    "                    validation_split=0.2, shuffle=True,\n",
    "                    epochs=150, batch_size=32, callbacks=[cb_checkpoint_xception])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fc33eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xception_acc = xception_history.history['accuracy']\n",
    "xception_val_acc = xception_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(xception_acc)+1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('xception_ Accuracy')\n",
    "plt.plot(epochs, xception_acc, 'b', label='train_acc')\n",
    "plt.plot(epochs, xception_val_acc, 'r', label='val_acc')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360e217d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 181s 2s/step - loss: 0.0349 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.034898173063993454, 0.9941666722297668]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xception = load_model(xception_path)\n",
    "xception_test_res = best_xception.evaluate(x_ts, y_test)\n",
    "xception_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6656bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 139s 1s/step\n",
      "time : 139.6585557460785\n",
      "pred shape: (3600, 30)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pred = best_xception.predict(x_ts)\n",
    "xception_pred_time = time.time()-start_time\n",
    "print(\"time : {}\".format(xception_pred_time))\n",
    "print(\"pred shape:\", pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192cc4a",
   "metadata": {},
   "source": [
    "### # 4개 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "524b7440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 정확도 & 예측 시간 비교\n",
    "\n",
    "test_results = [resNet_test_res[1], mobileNet_test_res[1], vgg16_test_res[1], xception_test_res[1]]\n",
    "pred_times = [resNet_pred_time, mobileNet_pred_time, vgg16_pred_time, xception_pred_time]\n",
    "total_params = [24115998, 3495006, 14849758, 21947078]\n",
    "models = [\"ResNet\", \"MobileNet\", \"VGG16\", \"Xception\"]\n",
    "\n",
    "data = [test_results, pred_times, total_params]\n",
    "titles = [\"Test Accuracy\", \"Prediction Time (3600 imgs)\", \"Total Parameters\"]\n",
    "xlabels = [\"Accuracy\", \"Prediction Time (s)\", \"Total Parameters\"]\n",
    "color = [\"mediumblue\",\"red\", \"green\"]\n",
    "y_pos = np.arange(len(models))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(3):\n",
    "    ax = plt.subplot(2, 2, i+1)              \n",
    "    ax.barh(y_pos, data[i], align='center', alpha=0.2, color=color[i], height=0.7)\n",
    "    ax.set_yticks(y_pos, models)\n",
    "    ax.set_xlabel(xlabels[i])\n",
    "    ax.set_title(titles[i])\n",
    "    for j, v in enumerate(y_pos):\n",
    "        ax.text(data[i][v], v, str(round(data[i][j], 2))   ,\n",
    "                 fontsize=9,\n",
    "                 color=\"black\",\n",
    "                 horizontalalignment='right',\n",
    "                 verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e46031",
   "metadata": {},
   "source": [
    "### # 결론\n",
    "* 4개의 모델 비교 결과, 총 파라미터 수가 가장 적고 예측시간이 가장 빠르면서도 정확도가 높은 MobileNet이 현재 데이터셋에는 가장 적합해 보임<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
